# app.py
import os
import re
import json
import math
import time
import random
import hashlib
import requests
import pandas as pd
import streamlit as st
import pydeck as pdk
from typing import Any, Optional
import logging
from dataclasses import dataclass, asdict
from pathlib import Path
from typing import List, Dict, Any, Tuple
from seoul_oa21050 import get_tour_places

# -----------------------------
# Page / Theme
# -----------------------------
st.set_page_config(
    page_title="ì„œìš¸ ë°©ë‘ì | Seoul Nomads",
    layout="wide",
)

# -----------------------------
# Constants / Defaults
# -----------------------------
APP_NAME_KR = "ì„œìš¸ ë°©ë‘ì"
APP_NAME_EN = "Seoul Nomads"

MAX_EXTRA_PEOPLE = 2  # user + up to 2
RECOMMEND_COUNT = 4
MAX_CANDIDATES = 600
MAX_CANDIDATES_RERANK = 1500

logger = logging.getLogger("recommender")
if not logger.handlers:
    logging.basicConfig(level=logging.INFO, format="%(levelname)s %(message)s")

REGIONS_JSON_PATH = Path("regions.json")
REGION_ASSETS_DIR = Path("assets/regions")
REGION_THUMBS_DIR = Path("assets/regions/thumbs")
REGIONS_META_PATH = Path("assets/regions/regions_meta.json")
PLACEHOLDER_IMAGE_PATH = Path("assets/placeholder.webp")

# ëŒ€í‘œ "ì§€ì—­(ë™ë„¤) í›„ë³´" ê¸°ë³¸ í’€ (API ì—°ë™ì´ ë¶ˆì™„ì „í•  ë•Œ fallback)
# ì‹¤ì œ ìš´ì˜ì—ì„œëŠ” ê´€ê´‘ëª…ì†Œ DB(OA-21050)ì—ì„œ ë™ë„¤/ê¶Œì—­ ë‹¨ìœ„ë¡œ ì§‘ê³„í•˜ê±°ë‚˜ ë³„ë„ ì§€ì—­ ë§ˆìŠ¤í„° í…Œì´ë¸”ì„ ê¶Œì¥
DEFAULT_AREAS = [
    {"area": "ì¸ì‚¬ë™", "gu": "ì¢…ë¡œêµ¬", "center": (37.5740, 126.9856), "addr": "ì„œìš¸íŠ¹ë³„ì‹œ ì¢…ë¡œêµ¬ ì¸ì‚¬ë™ ì¼ëŒ€"},
    {"area": "ì„±ìˆ˜", "gu": "ì„±ë™êµ¬", "center": (37.5445, 127.0566), "addr": "ì„œìš¸íŠ¹ë³„ì‹œ ì„±ë™êµ¬ ì„±ìˆ˜ë™ ì¼ëŒ€"},
    {"area": "ì—°ë‚¨", "gu": "ë§ˆí¬êµ¬", "center": (37.5637, 126.9216), "addr": "ì„œìš¸íŠ¹ë³„ì‹œ ë§ˆí¬êµ¬ ì—°ë‚¨ë™ ì¼ëŒ€"},
    {"area": "í•œë‚¨", "gu": "ìš©ì‚°êµ¬", "center": (37.5343, 127.0067), "addr": "ì„œìš¸íŠ¹ë³„ì‹œ ìš©ì‚°êµ¬ í•œë‚¨ë™ ì¼ëŒ€"},
    {"area": "ì‚¼ì²­ë™", "gu": "ì¢…ë¡œêµ¬", "center": (37.5826, 126.9816), "addr": "ì„œìš¸íŠ¹ë³„ì‹œ ì¢…ë¡œêµ¬ ì‚¼ì²­ë™ ì¼ëŒ€"},
    {"area": "ì´íƒœì›", "gu": "ìš©ì‚°êµ¬", "center": (37.5346, 126.9946), "addr": "ì„œìš¸íŠ¹ë³„ì‹œ ìš©ì‚°êµ¬ ì´íƒœì›ë™ ì¼ëŒ€"},
    {"area": "ì—¬ì˜ë„", "gu": "ì˜ë“±í¬êµ¬", "center": (37.5219, 126.9246), "addr": "ì„œìš¸íŠ¹ë³„ì‹œ ì˜ë“±í¬êµ¬ ì—¬ì˜ë„ ì¼ëŒ€"},
    {"area": "ì ì‹¤", "gu": "ì†¡íŒŒêµ¬", "center": (37.5133, 127.1028), "addr": "ì„œìš¸íŠ¹ë³„ì‹œ ì†¡íŒŒêµ¬ ì ì‹¤ë™ ì¼ëŒ€"},
    {"area": "ì„œì´Œ", "gu": "ì¢…ë¡œêµ¬", "center": (37.5793, 126.9689), "addr": "ì„œìš¸íŠ¹ë³„ì‹œ ì¢…ë¡œêµ¬ ì„œì´Œ(í†µì¸/íš¨ìë™) ì¼ëŒ€"},
    {"area": "ìµì„ ë™", "gu": "ì¢…ë¡œêµ¬", "center": (37.5759, 126.9897), "addr": "ì„œìš¸íŠ¹ë³„ì‹œ ì¢…ë¡œêµ¬ ìµì„ ë™ ì¼ëŒ€"},
]

# êµ¬ ëª©ë¡ (ê´€ê´‘ëª…ì†Œ ì¸ë±ì‹± ìµœì í™”ìš©)
GU_LIST = tuple(sorted({a["gu"] for a in DEFAULT_AREAS}))

# ê°„ì´ "ì¸ê·¼ ì¶”ì²œ" (ì‹¤ì„œë¹„ìŠ¤ì—ì„œëŠ” ê·¸ë˜í”„/ê±°ë¦¬ ê¸°ë°˜ ì¶”ì²œ ê¶Œì¥)
NEARBY_BEST = {
    "ì¸ì‚¬ë™": ["ë¶ì´Œ í•œì˜¥ë§ˆì„", "ì‚¼ì²­ë™"],
    "ì‚¼ì²­ë™": ["ë¶ì´Œ í•œì˜¥ë§ˆì„", "ì¸ì‚¬ë™"],
    "ì„œì´Œ": ["ê²½ë³µê¶", "ê´‘í™”ë¬¸"],
    "ìµì„ ë™": ["ì¸ì‚¬ë™", "ì¢…ë¡œ1ê°€"],
    "ì„±ìˆ˜": ["ì„œìš¸ìˆ²", "ëšì„¬"],
    "ì—°ë‚¨": ["í™ëŒ€", "í•©ì •"],
    "í•œë‚¨": ["ì´íƒœì›", "ìš©ì‚°"],
    "ì´íƒœì›": ["í•œë‚¨", "ìš©ì‚°"],
    "ì—¬ì˜ë„": ["ë”í˜„ëŒ€ ì„œìš¸", "í•œê°•ê³µì›(ì—¬ì˜ë„)"],
    "ì ì‹¤": ["ì„ì´Œí˜¸ìˆ˜", "ì†¡ë¦¬ë‹¨ê¸¸"],
}

# ê°„ì´ ì§€í•˜ì² ì—­(500m) ì˜ˆì‹œ (ì‹¤ì„œë¹„ìŠ¤ì—ì„œëŠ” ì—­ ì¢Œí‘œ ë°ì´í„° + ê±°ë¦¬ ê³„ì‚° í•„ìš”)
NEARBY_STATIONS = {
    "ì¸ì‚¬ë™": ["ì•ˆêµ­ì—­ (3í˜¸ì„ )", "ì¢…ê°ì—­ (1í˜¸ì„ )"],
    "ì‚¼ì²­ë™": ["ì•ˆêµ­ì—­ (3í˜¸ì„ )"],
    "ì„œì´Œ": ["ê²½ë³µê¶ì—­ (3í˜¸ì„ )", "ê´‘í™”ë¬¸ì—­ (5í˜¸ì„ )"],
    "ìµì„ ë™": ["ì¢…ë¡œ3ê°€ì—­ (1/3/5í˜¸ì„ )", "ì•ˆêµ­ì—­ (3í˜¸ì„ )"],
    "ì„±ìˆ˜": ["ì„±ìˆ˜ì—­ (2í˜¸ì„ )", "ëšì„¬ì—­ (2í˜¸ì„ )"],
    "ì—°ë‚¨": ["í™ëŒ€ì…êµ¬ì—­ (2/ê²½ì˜ì¤‘ì•™/ê³µí•­ì² ë„)"],
    "í•œë‚¨": ["í•œê°•ì§„ì—­ (6í˜¸ì„ )"],
    "ì´íƒœì›": ["ì´íƒœì›ì—­ (6í˜¸ì„ )", "í•œê°•ì§„ì—­ (6í˜¸ì„ )"],
    "ì—¬ì˜ë„": ["ì—¬ì˜ë„ì—­ (5/9í˜¸ì„ )", "ì—¬ì˜ë‚˜ë£¨ì—­ (5í˜¸ì„ )"],
    "ì ì‹¤": ["ì ì‹¤ì—­ (2/8í˜¸ì„ )", "ì ì‹¤ë‚˜ë£¨ì—­ (2í˜¸ì„ )"],
}

CROWD_LEVELS = ["ì—¬ìœ ", "ì•½ê°„ ë¶ë¹”", "ë¶ë¹”"]
CROWD_COLOR = {
    "ì—¬ìœ ": "green",
    "ì•½ê°„ ë¶ë¹”": "orange",
    "ë¶ë¹”": "red",
}

# -----------------------------
# Helpers: Session State
# -----------------------------
def init_state():
    if "people" not in st.session_state:
        st.session_state.people = [default_person(is_me=True)]
    if "disliked" not in st.session_state:
        # key: signature(str) -> set(area_names)
        st.session_state.disliked = {}
    if "last_reco" not in st.session_state:
        st.session_state.last_reco = []
    if "last_signature" not in st.session_state:
        st.session_state.last_signature = ""
    if "reco_signature" not in st.session_state:
        st.session_state.reco_signature = ""
    if "seen_place_ids" not in st.session_state:
        st.session_state.seen_place_ids = set()
    if "feed_buffer" not in st.session_state:
        st.session_state.feed_buffer = []
    if "master_pool" not in st.session_state:
        st.session_state.master_pool = []
    if "cursor" not in st.session_state:
        st.session_state.cursor = 0
    if "pool_limit" not in st.session_state:
        st.session_state.pool_limit = 0


# -----------------------------
# Data structures
# -----------------------------
@dataclass
class StartLocation:
    scope: str  # "ì„œìš¸ ë‚´" / "ì„œìš¸ ì™¸ë¶€"
    si: str = ""       # ì„œìš¸ ì™¸ë¶€ ì„ íƒ ì‹œ
    gu: str = ""       # ì„œìš¸ ë‚´ ì„ íƒ ì‹œ
    dong: str = ""     # ê³µí†µ

@dataclass
class PersonInput:
    is_me: bool
    relationship: str
    taste: str
    purpose: str
    start_location: StartLocation

def default_person(is_me: bool = False) -> PersonInput:
    return PersonInput(
        is_me=is_me,
        relationship="ë³¸ì¸" if is_me else "",
        taste="",
        purpose="",
        start_location=StartLocation(scope="ì„œìš¸ ë‚´", gu="", dong="", si=""),
    )


# -----------------------------
# Signature (ì¡°ê±´ ë³€ê²½ ê°ì§€ / ë¹„ì„ í˜¸ ì¬ë“±ì¥ ë°©ì§€)
# -----------------------------
def make_signature(main_taste: str, main_purpose: str, crowd_pref: str, people: List[PersonInput]) -> str:
    # ì¡°ê±´ì´ ë™ì¼í•˜ë©´ ê°™ì€ signatureê°€ ë˜ë„ë¡ ì •ê·œí™”
    def norm(s: str) -> str:
        s = (s or "").strip().lower()
        s = re.sub(r"\s+", " ", s)
        return s

    core = {
        "main_taste": norm(main_taste),
        "main_purpose": norm(main_purpose),
        "crowd_pref": crowd_pref,
        "people": [
            {
                "rel": norm(p.relationship),
                "taste": norm(p.taste),
                "purpose": norm(p.purpose),
                "loc": {
                    "scope": p.start_location.scope,
                    "si": norm(p.start_location.si),
                    "gu": norm(p.start_location.gu),
                    "dong": norm(p.start_location.dong),
                },
            }
            for p in people
            if not p.is_me  # ë™í–‰ìë§Œ ë°˜ì˜(ë³¸ì¸ì€ mainìœ¼ë¡œ ì´ë¯¸ ìˆìŒ)
        ],
    }
    return json.dumps(core, ensure_ascii=False, sort_keys=True)


# -----------------------------
# OpenAI (ì¶”ì²œ ì´ìœ /ì½”ìŠ¤ ë¬¸êµ¬ ìƒì„±)
# -----------------------------
def generate_reason_with_openai(
    openai_api_key: str,
    area_name: str,
    crowd_label: str,
    main_taste: str,
    main_purpose: str,
    extra_context: Dict[str, Any],
) -> Dict[str, Any]:
    """
    ë°˜í™˜ í˜•ì‹:
    {
      "one_liner": "3ë¬¸ì¥",
      "bullets": [],
      "course": {}
    }
    """
    # í‚¤ê°€ ì—†ìœ¼ë©´ í…œí”Œë¦¿ í…ìŠ¤íŠ¸ë¡œ fallback
    if not openai_api_key:
        taste = main_taste or "ë‹¤ì–‘í•œ ì·¨í–¥"
        purpose = main_purpose or "ì—¬ëŸ¬ ëª©ì "
        fallback = (
            f"{area_name}ì€(ëŠ”) {taste}ê³¼(ì™€) {purpose}ì— ë§ì¶˜ ë™ì„ ì´ ì˜ ë§ìŠµë‹ˆë‹¤. "
            "ì£¼ë³€ì— ì„ íƒì§€ê°€ ëª¨ì—¬ ìˆì–´ ì¼ì • êµ¬ì„± ë¶€ë‹´ì´ ë‚®ìŠµë‹ˆë‹¤. "
            "ì·¨í–¥ í‚¤ì›Œë“œì™€ ì—°ê²°ëœ í¬ì¸íŠ¸ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ì½”ìŠ¤ë¥¼ ì¡ê¸° ì¢‹ìŠµë‹ˆë‹¤."
        )
        return {
            "one_liner": fallback,
            "bullets": split_sentences_for_bullets(fallback),
            "course": {
                "culture": [],
                "cafe": [],
                "food": [],
                "activity": [],
            },
        }

    # OpenAI ìµœì‹  SDKë¥¼ ì“°ì§€ ì•Šê³ ë„ ë™ì‘ ê°€ëŠ¥í•˜ê²Œ "HTTP í˜¸ì¶œ" í˜•íƒœë¡œ êµ¬ì„± (í™˜ê²½ë³„ ìœ ì—°ì„±)
    # ì‚¬ìš©ìê°€ ì„¤ì¹˜í•œ í™˜ê²½ì— ë”°ë¼ SDKë¥¼ ë¶™ì¼ ìˆ˜ë„ ìˆìŒ.
    # ëª¨ë¸ëª…ì€ í™˜ê²½ì— ë§ê²Œ ì¡°ì • ê°€ëŠ¥.
    url = "https://api.openai.com/v1/chat/completions"
    headers = {
        "Authorization": f"Bearer {openai_api_key}",
        "Content-Type": "application/json",
    }

    sys = (
        "ë„ˆëŠ” ì„œìš¸ ë‚´ ì•½ì†/ë°ì´íŠ¸ ì¥ì†Œ ì¶”ì²œ ì„œë¹„ìŠ¤ì˜ ì¹´í”¼ë¼ì´í„°ë‹¤. "
        "ê³¼ì¥ ì—†ì´, 3ë¬¸ì¥ìœ¼ë¡œë§Œ ì‘ì„±í•œë‹¤. "
        "ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì·¨í–¥/ëª©ì  í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ë°˜ë“œì‹œ ë¬¸ì¥ì— í¬í•¨í•œë‹¤. "
        "ì´ëª¨ì§€ëŠ” ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ”ë‹¤. "
        "ì¶”ì²œ ì´ìœ ëŠ” bullets(3ë¬¸ì¥ ë¦¬ìŠ¤íŠ¸)ë¡œë„ ë°˜í™˜í•˜ê³ , "
        "ìƒì„¸ ì½”ìŠ¤ëŠ” culture/cafe/food/activity ê° 2~3ê°œì”© ê°„ë‹¨ í‚¤ì›Œë“œë¡œ ì œì‹œí•œë‹¤. "
        "ì¶œë ¥ì€ ë°˜ë“œì‹œ JSONë§Œ ë°˜í™˜í•œë‹¤."
    )

    user = {
        "area": area_name,
        "crowd": crowd_label,
        "taste": main_taste,
        "purpose": main_purpose,
        "context": extra_context,
        "format": {
            "one_liner": "3 sentences string",
            "bullets": ["sentence1", "sentence2", "sentence3"],
            "course": {
                "culture": ["string", "string"],
                "cafe": ["string", "string"],
                "food": ["string", "string"],
                "activity": ["string", "string"]
            }
        }
    }

    payload = {
        "model": "gpt-4o-mini",  # í•„ìš” ì‹œ ë³€ê²½
        "messages": [
            {"role": "system", "content": sys},
            {"role": "user", "content": json.dumps(user, ensure_ascii=False)}
        ],
        "temperature": 0.6,
        "response_format": {"type": "json_object"},
    }

    try:
        resp = requests.post(url, headers=headers, json=payload, timeout=20)
        resp.raise_for_status()
        content = resp.json()["choices"][0]["message"]["content"]
        data = json.loads(content)
        # ê¸°ë³¸ í‚¤ ë³´ì •
        data.setdefault("one_liner", "")
        bullets = data.get("bullets") or []
        if not isinstance(bullets, list):
            bullets = []
        if not bullets and data.get("one_liner"):
            bullets = split_sentences_for_bullets(str(data.get("one_liner")))
        data["bullets"] = bullets
        course = data.get("course") or {}
        if not isinstance(course, dict):
            course = {}
        data["course"] = course
        return data
    except Exception:
        # ì¥ì•  ì‹œ fallback
        taste = main_taste or "ë‹¤ì–‘í•œ ì·¨í–¥"
        purpose = main_purpose or "ì—¬ëŸ¬ ëª©ì "
        fallback = (
            f"{area_name}ì€(ëŠ”) {taste}ê³¼(ì™€) {purpose}ì— ë§ì¶˜ ë™ì„ ì´ ì˜ ë§ìŠµë‹ˆë‹¤. "
            "ì£¼ë³€ì— ì„ íƒì§€ê°€ ëª¨ì—¬ ìˆì–´ ì¼ì • êµ¬ì„± ë¶€ë‹´ì´ ë‚®ìŠµë‹ˆë‹¤. "
            "ì·¨í–¥ í‚¤ì›Œë“œì™€ ì—°ê²°ëœ í¬ì¸íŠ¸ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ì½”ìŠ¤ë¥¼ ì¡ê¸° ì¢‹ìŠµë‹ˆë‹¤."
        )
        return {
            "one_liner": fallback,
            "bullets": split_sentences_for_bullets(fallback),
            "course": {
                "culture": [],
                "cafe": [],
                "food": [],
                "activity": [],
            },
        }


# -----------------------------
# OpenAI (í‚¤ì›Œë“œ í™•ì¥ / ì¬ë­í‚¹)
# -----------------------------
def expand_keywords_with_openai(
    openai_api_key: str,
    main_taste: str,
    main_purpose: str,
    extra_people: List[PersonInput],
) -> List[str]:
    if not openai_api_key:
        return []

    url = "https://api.openai.com/v1/chat/completions"
    headers = {
        "Authorization": f"Bearer {openai_api_key}",
        "Content-Type": "application/json",
    }

    user = {
        "taste": main_taste,
        "purpose": main_purpose,
        "companions": [
            {"relationship": p.relationship, "taste": p.taste, "purpose": p.purpose}
            for p in extra_people
        ],
        "format": {"keywords": ["string", "string", "string"]},
    }

    payload = {
        "model": "gpt-4o-mini",
        "messages": [
            {"role": "system", "content": "í‚¤ì›Œë“œ í™•ì¥ê¸°. JSONë§Œ ë°˜í™˜."},
            {"role": "user", "content": json.dumps(user, ensure_ascii=False)},
        ],
        "temperature": 0.4,
        "response_format": {"type": "json_object"},
    }

    try:
        resp = requests.post(url, headers=headers, json=payload, timeout=20)
        resp.raise_for_status()
        content = resp.json()["choices"][0]["message"]["content"]
        data = json.loads(content)
        kws = data.get("keywords", [])
        if isinstance(kws, list):
            return [str(k).strip() for k in kws if str(k).strip()]
        return []
    except Exception:
        return []


def rerank_areas_with_openai(
    openai_api_key: str,
    main_taste: str,
    main_purpose: str,
    extra_people: List[PersonInput],
    candidates: List[Dict[str, Any]],
) -> List[str]:
    if not openai_api_key:
        return []

    url = "https://api.openai.com/v1/chat/completions"
    headers = {
        "Authorization": f"Bearer {openai_api_key}",
        "Content-Type": "application/json",
    }

    user = {
        "taste": main_taste,
        "purpose": main_purpose,
        "companions": [
            {"relationship": p.relationship, "taste": p.taste, "purpose": p.purpose}
            for p in extra_people
        ],
        "candidates": [
            {
                "area": c.get("area"),
                "gu": c.get("gu"),
                "crowd": c.get("crowd_now"),
                "score_hint": round(float(c.get("score", 0.0)), 2),
                "keyword_hits": c.get("keyword_hits", []),
            }
            for c in candidates
        ],
        "format": {"ranked": ["area_name"]},
    }

    payload = {
        "model": "gpt-4o-mini",
        "messages": [
            {"role": "system", "content": "ì¶”ì²œ ì§€ì—­ ì¬ë­í‚¹. JSONë§Œ ë°˜í™˜."},
            {"role": "user", "content": json.dumps(user, ensure_ascii=False)},
        ],
        "temperature": 0.3,
        "response_format": {"type": "json_object"},
    }

    try:
        resp = requests.post(url, headers=headers, json=payload, timeout=20)
        resp.raise_for_status()
        content = resp.json()["choices"][0]["message"]["content"]
        data = json.loads(content)
        ranked = data.get("ranked", [])
        if isinstance(ranked, list):
            return [str(r).strip() for r in ranked if str(r).strip()]
        return []
    except Exception:
        return []


# ë¹ ë¥¸ í…œí”Œë¦¿ ë¬¸êµ¬ (ë¦¬ìŠ¤íŠ¸ í™”ë©´ìš©)
def quick_reason_template(area_name: str, crowd_label: str, main_taste: str, main_purpose: str) -> str:
    taste = main_taste or "ë‹¤ì–‘í•œ ì·¨í–¥"
    purpose = main_purpose or "ì—¬ëŸ¬ ëª©ì "
    return f"{area_name}ì€(ëŠ”) {taste}ê³¼(ì™€) {purpose}ì— ë§ì¶° ë™ì„ ì´ ê¹”ë”í•©ë‹ˆë‹¤."


@st.cache_data(ttl=3600)
def generate_reason_cached(
    openai_api_key: str,
    area_name: str,
    crowd_label: str,
    main_taste: str,
    main_purpose: str,
    extra_context: Dict[str, Any],
) -> Dict[str, Any]:
    return generate_reason_with_openai(
        openai_api_key=openai_api_key,
        area_name=area_name,
        crowd_label=crowd_label,
        main_taste=main_taste,
        main_purpose=main_purpose,
        extra_context=extra_context,
    )


# -----------------------------
# Seoul Open Data: Real-time population (OA-21778) - ìë¦¬/íŒŒì‹± TODO
# -----------------------------
@st.cache_data(ttl=60)
def fetch_seoul_realtime_population(seoul_api_key: str) -> Dict[str, Any]:
    """
    ì„œìš¸ ì—´ë¦°ë°ì´í„°ê´‘ì¥ 'ì„œìš¸ì‹œ ì‹¤ì‹œê°„ ì¸êµ¬ ë°ì´í„°' API í˜¸ì¶œ ê²°ê³¼ rawë¥¼ ë°˜í™˜.
    ì‹¤ì œ URL/íŒŒë¼ë¯¸í„°ëŠ” ë°œê¸‰í‚¤ ìœ í˜•ê³¼ ë¬¸ì„œì— ë§ê²Œ ì¡°ì • í•„ìš”.
    """
    if not seoul_api_key:
        return {}

    # TODO: ì•„ë˜ URLì€ ì˜ˆì‹œ í˜•íƒœì…ë‹ˆë‹¤. ì‹¤ì œ ì—”ë“œí¬ì¸íŠ¸/ì„œë¹„ìŠ¤ëª…ì€ OA-21778 ë¬¸ì„œì— ë§ì¶° ìˆ˜ì •í•˜ì„¸ìš”.
    # ì˜ˆ) http://openapi.seoul.go.kr:8088/{KEY}/json/citydata/1/5/
    url = f"http://openapi.seoul.go.kr:8088/{seoul_api_key}/json/citydata/1/200/"
    try:
        r = requests.get(url, timeout=15)
        r.raise_for_status()
        return r.json()
    except Exception:
        return {}

def crowd_label_from_population(area_name: str, crowd_pref: str, pop_raw: Dict[str, Any]) -> str:
    """
    area_nameë³„ í˜¼ì¡ë„ë¥¼ ì‚°ì¶œ.
    ì‹¤ì œë¡œëŠ” API ì‘ë‹µì—ì„œ í•´ë‹¹ area_name(ë˜ëŠ” ì¥ì†Œì½”ë“œ)ì— ë§¤ì¹­ë˜ëŠ” í•­ëª©ì˜ í˜¼ì¡ë„ë¥¼ ì½ì–´ì•¼ í•¨.
    ì—¬ê¸°ì„œëŠ” (1) API ì‘ë‹µ ë§¤ì¹­ ì‹¤íŒ¨ ì‹œ (2) crowd_prefë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©.
    """
    # TODO: pop_raw íŒŒì‹±/ë§¤ì¹­ ë¡œì§ì„ OA-21778 ì‘ë‹µ êµ¬ì¡°ì— ë§ê²Œ êµ¬í˜„
    # ì‘ë‹µì—ì„œ 'AREA_NM', 'AREA_CONGEST_LVL' ê°™ì€ í•„ë“œê°€ ìˆì„ ê°€ëŠ¥ì„±ì´ í¼.
    # ì•„ë˜ëŠ” ì˜ˆì‹œ:
    try:
        # ì˜ˆì‹œ: pop_raw["CITYDATA"]["row"] êµ¬ì¡° ê°€ì • (ì‹¤ì œì™€ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ)
        rows = pop_raw.get("CITYDATA", {}).get("row", [])
        for row in rows:
            if str(row.get("AREA_NM", "")).strip() == area_name:
                lvl = str(row.get("AREA_CONGEST_LVL", "")).strip()
                if lvl in CROWD_LEVELS:
                    return lvl
    except Exception:
        pass

    # fallback: ì‚¬ìš©ìê°€ ì„ íƒí•œ í¬ë§ í˜¼ì¡ë„
    return crowd_pref


# -----------------------------
# Seoul Open Data: Tourist attractions (OA-21050) - ìë¦¬/íŒŒì‹± TODO
# -----------------------------
@st.cache_data(ttl=3600)
def fetch_seoul_tour_spots(seoul_api_key: str) -> List[Dict[str, Any]]:
    """
    'ì„œìš¸ ê´€ê´‘ëª…ì†Œ ë°ì´í„° DB' raw ëª©ë¡ ë°˜í™˜.
    ì‹¤ì œ URL/ì„œë¹„ìŠ¤ëª…/í•„ë“œëŠ” OA-21050 ë¬¸ì„œì— ë§ê²Œ ìˆ˜ì • í•„ìš”.
    """
    if not seoul_api_key:
        return []

    # TODO: ì•„ë˜ URLì€ ì˜ˆì‹œ í˜•íƒœì…ë‹ˆë‹¤. ì‹¤ì œ ì„œë¹„ìŠ¤ëª…/ì—”ë“œí¬ì¸íŠ¸ëŠ” OA-21050ì— ë§ê²Œ ìˆ˜ì •í•˜ì„¸ìš”.
    # ì˜ˆ) http://openapi.seoul.go.kr:8088/{KEY}/json/<SERVICE>/1/1000/
    url = f"http://openapi.seoul.go.kr:8088/{seoul_api_key}/json/seoultour/1/1000/"
    try:
        r = requests.get(url, timeout=20)
        r.raise_for_status()
        data = r.json()

        # TODO: data êµ¬ì¡°ì— ë§ê²Œ row ì¶”ì¶œ
        # ì˜ˆì‹œ: data["seoultour"]["row"]
        rows = []
        for k in data.keys():
            if isinstance(data[k], dict) and "row" in data[k]:
                rows = data[k]["row"]
                break
        if not isinstance(rows, list):
            return []
        return rows
    except Exception:
        return []


# -----------------------------
# Tourist spots index (precompute search text per gu)
# -----------------------------
@st.cache_data(ttl=21600)
def build_tour_spot_index(tour_spots: List[Dict[str, Any]], gu_list: Tuple[str, ...]) -> Dict[str, List[str]]:
    """
    ê´€ê´‘ëª…ì†Œ row í…ìŠ¤íŠ¸ë¥¼ ë¯¸ë¦¬ í•©ì³ë‘ê³  êµ¬(gu)ë³„ë¡œ ì¸ë±ì‹±.
    ì¶”ì²œ ì‹œ ë°˜ë³µ ë¬¸ìì—´ í•©ì¹˜ê¸°/í•„í„°ë§ ë¹„ìš©ì„ ì¤„ì¸ë‹¤.
    """
    index: Dict[str, List[str]] = {gu: [] for gu in gu_list}
    if not tour_spots:
        return index

    for row in tour_spots:
        if not isinstance(row, dict):
            continue
        text = " ".join([str(v) for v in row.values() if isinstance(v, (str, int, float))]).lower()
        if not text:
            continue
        for gu in gu_list:
            if gu in text:
                index[gu].append(text)
    return index


def _get_first_value(row: Dict[str, Any], keys: List[str]) -> str:
    for k in keys:
        if k in row and row[k]:
            return str(row[k]).strip()
        lk = k.lower()
        for key in row.keys():
            if key.lower() == lk and row[key]:
                return str(row[key]).strip()
    return ""


def _parse_float(v: Any) -> Optional[float]:
    try:
        return float(str(v).strip())
    except Exception:
        return None


def build_region_candidates_from_places(
    places: List[Dict[str, Any]],
) -> Tuple[List[Dict[str, Any]], bool, str]:
    """
    OA-21050 placesë¥¼ gu ê¸°ì¤€ ì§€ì—­ í›„ë³´ë¡œ ë¬¶ëŠ”ë‹¤.
    guê°€ ì—†ëŠ” placeëŠ” 'ê¸°íƒ€' ê·¸ë£¹ìœ¼ë¡œ í¬í•¨í•œë‹¤.
    ë°˜í™˜: (candidates, fallback_used, fallback_reason)
    """
    if not places:
        return [], True, "places empty"

    grouped: Dict[str, List[Dict[str, Any]]] = {}
    for p in places:
        gu = (p.get("gu") or "").strip() or "ê¸°íƒ€"
        grouped.setdefault(gu, []).append(p)

    candidates: List[Dict[str, Any]] = []
    for gu, ps in grouped.items():
        lats = [p.get("lat") for p in ps if isinstance(p.get("lat"), (int, float))]
        lngs = [p.get("lng") for p in ps if isinstance(p.get("lng"), (int, float))]
        center = None
        if lats and lngs:
            center = (sum(lats) / len(lats), sum(lngs) / len(lngs))
        candidates.append(
            {
                "area": gu,
                "gu": gu if gu != "ê¸°íƒ€" else "",
                "center": center or (37.5665, 126.9780),
                "addr": f"ì„œìš¸íŠ¹ë³„ì‹œ {gu}" if gu != "ê¸°íƒ€" else "ì„œìš¸íŠ¹ë³„ì‹œ",
                "places": ps,
                "place_count": len(ps),
                "has_center": bool(center),
            }
        )

    if not candidates:
        return [], True, "no groups"

    candidates.sort(key=lambda x: x.get("place_count", 0), reverse=True)
    return candidates[:MAX_CANDIDATES], False, ""


def build_place_candidates_from_places(
    places: List[Dict[str, Any]],
    limit: int = MAX_CANDIDATES,
) -> List[Dict[str, Any]]:
    """
    placesì—ì„œ ê°œë³„ POI í›„ë³´ ë¦¬ìŠ¤íŠ¸ ìƒì„± (top-upìš©).
    """
    candidates: List[Dict[str, Any]] = []
    seen = set()
    for p in places:
        lat = p.get("lat")
        lng = p.get("lng")
        if isinstance(lat, (int, float)) and isinstance(lng, (int, float)):
            center = (lat, lng)
            key = f"{p.get('name','')}|{lat:.5f}|{lng:.5f}"
        else:
            center = (37.5665, 126.9780)
            key = f"{p.get('name','')}|no-coords"
        if key in seen:
            continue
        seen.add(key)
        name = (p.get("name") or "").strip()
        address = (p.get("address") or "").strip()
        if is_excluded_place(name, address):
            continue
        dong = extract_dong_from_place(p)
        if not dong:
            continue
        if not is_korean_text(dong):
            continue
        candidates.append(
            {
                "area": dong,
                "gu": p.get("gu") or "",
                "center": center,
                "addr": p.get("address") or "",
                "place_id": p.get("place_id"),
                "tags": p.get("tags") or [],
                "description": p.get("description"),
                "homepage_url": p.get("homepage_url"),
            }
        )
    return candidates[:limit]


# -----------------------------
# Utility: text scoring
# -----------------------------
def tokenize_korean_keywords(text: str) -> List[str]:
    if not text:
        return []
    # ì•„ì£¼ ë‹¨ìˆœ í† í°í™” (ìš´ì˜ì—ì„œëŠ” í˜•íƒœì†Œ ë¶„ì„/ì„ë² ë”© ì¶”ì²œ)
    text = re.sub(r"[^\w\sê°€-í£]", " ", text)
    toks = [t.strip().lower() for t in text.split() if t.strip()]
    # ë„ˆë¬´ ì§§ì€ í† í° ì œê±°
    return [t for t in toks if len(t) >= 2]

def split_sentences_for_bullets(text: str) -> List[str]:
    if not text:
        return []
    parts = re.split(r"(?<=[.!?ã€‚])\s+", text.strip())
    bullets = []
    for p in parts:
        p = p.strip()
        if not p:
            continue
        bullets.append(p)
    # í•œê¸€ ë¬¸ì¥ ë§ˆì¹¨í‘œê°€ ì—†ì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ê¸¸ê²Œ ë‚¨ì€ ë¬¸ì¥ì„ 3ê°œë¡œ ë¶„í• 
    if len(bullets) <= 1 and len(text) > 30:
        chunks = re.split(r"[;â€¢]", text)
        for c in chunks:
            c = c.strip()
            if c and c not in bullets:
                bullets.append(c)
    return bullets[:3]


def to_korean_display(text: str) -> str:
    if not text:
        return ""
    # í•œê¸€/ìˆ«ì/ê³µë°±/í•˜ì´í”ˆë§Œ ë‚¨ê¹€
    cleaned = re.sub(r"[^0-9ê°€-í£\s\-]", "", text)
    cleaned = re.sub(r"\s+", " ", cleaned).strip()
    return cleaned


def is_korean_text(text: str) -> bool:
    if not text:
        return False
    return bool(re.search(r"[ê°€-í£]", text))


def is_excluded_place(name: str, address: str = "") -> bool:
    target = f"{name} {address}".strip()
    return "ì•ˆë…•ì¸ì‚¬ë™" in target


def to_road_address(text: str) -> str:
    if not text:
        return ""
    cleaned = to_korean_display(text)
    # ìˆ«ì ì œê±°
    cleaned = re.sub(r"\d+", "", cleaned).strip()
    cleaned = re.sub(r"\s+", " ", cleaned).strip()
    # ì„œìš¸-êµ¬-ë™ê¹Œì§€ë§Œ í‘œê¸°
    m = re.search(r"(ì„œìš¸\s*[ê°€-í£]{2,4}êµ¬\s*[ê°€-í£]{2,4}ë™)", cleaned)
    if m:
        return m.group(1).replace("  ", " ").strip()
    # ë™ê¹Œì§€ë§Œ ìˆëŠ” ê²½ìš°
    m = re.search(r"([ê°€-í£]{2,4}êµ¬\s*[ê°€-í£]{2,4}ë™)", cleaned)
    if m:
        return f"ì„œìš¸ {m.group(1)}".strip()
    return cleaned


def render_bullet_list(items: List[str]) -> None:
    if not items:
        return
    safe_items = [to_korean_display(i) if isinstance(i, str) else str(i) for i in items if str(i).strip()]
    if not safe_items:
        return
    bullets_html = "".join([f"<li style='margin-bottom:6px;'>{i}</li>" for i in safe_items])
    st.markdown(
        f"<ul style='margin:0 0 0 18px; padding:0; color:#333;'>{bullets_html}</ul>",
        unsafe_allow_html=True,
    )


def pick_korean_name(*candidates: str) -> str:
    # í›„ë³´ ë¬¸ìì—´ì—ì„œ í•œê¸€ í† í°ì„ ì¶”ì¶œí•´ ê°€ì¥ ê¸´ ê²ƒì„ ì„ íƒ
    best = ""
    for text in candidates:
        if not text:
            continue
        # í•œê¸€ ì—°ì† ë¬¸ìì—´ë“¤ ì¶”ì¶œ
        parts = re.findall(r"[ê°€-í£]{2,}", str(text))
        if parts:
            parts.sort(key=len, reverse=True)
            if len(parts[0]) > len(best):
                best = parts[0]
    return best


def extract_dong(text: str) -> str:
    if not text:
        return ""
    m = re.search(r"([ê°€-í£]{2,4}ë™)", text)
    if m:
        return m.group(1)
    m = re.search(r"([A-Za-z\\-]+)-dong", text)
    if m:
        return f"{m.group(1)}-dong"
    return ""


def is_dong_name(name: str) -> bool:
    if not name:
        return False
    return bool(re.search(r"[ê°€-í£]{2,4}ë™", name))


def extract_dong_from_place(p: Dict[str, Any]) -> str:
    """
    ì¥ì†Œ ë ˆì½”ë“œì—ì„œ ë™ëª…ì„ ì¶”ì¶œ.
    ì£¼ì†Œ ìš°ì„ , ì—†ìœ¼ë©´ ëª…ì¹­ì—ì„œë„ ì¶”ì¶œ.
    """
    dong = extract_dong(p.get("address") or "")
    if not dong:
        dong = extract_dong(p.get("name") or "")
    return dong

def score_area_by_preferences(
    area: Dict[str, Any],
    main_taste: str,
    main_purpose: str,
    crowd_pref: str,
    crowd_now: str,
    tour_spot_index: Dict[str, List[str]],
    extra_people: List[PersonInput],
    extra_keywords: List[str],
) -> float:
    """
    ê°„ë‹¨ ìŠ¤ì½”ì–´ë§:
    - í…ìŠ¤íŠ¸(ì·¨í–¥/ëª©ì ) í‚¤ì›Œë“œê°€ ê´€ê´‘ëª…ì†Œ rowì˜ ì„¤ëª…/ëª…ì¹­/ë¶„ë¥˜ ë“±ì— ì–¼ë§ˆë‚˜ ë“±ì¥í•˜ëŠ”ì§€
    - í˜¼ì¡ë„ ì„ í˜¸ì™€ í˜„ì¬ í˜¼ì¡ë„ ì¼ì¹˜ ê°€ì 
    - ë™í–‰ì ì·¨í–¥/ëª©ì ë„ ë™ì¼ ë°©ì‹ìœ¼ë¡œ ê°€ì (ê³µë€ì´ë©´ ë¬´ì‹œ)
    """
    base = 0.0

    # crowd match score
    if crowd_now == crowd_pref:
        base += 2.0
    else:
        # ì„ í˜¸ì™€ ì‹¤ì œ ì°¨ì´ê°€ í¬ë©´ ê°ì  (ì—¬ìœ <->ë¶ë¹”)
        dist = abs(CROWD_LEVELS.index(crowd_now) - CROWD_LEVELS.index(crowd_pref))
        base += max(0.0, 1.5 - 0.7 * dist)

    # keyword score from tour DB
    # TODO: OA-21050 í•„ë“œì— ë§ê²Œ area ë§¤ì¹­(êµ¬/ë™/ê¶Œì—­/ì¢Œí‘œ ê¸°ë°˜)ì„ ì •êµí™” ê¶Œì¥
    # ì—¬ê¸°ì„œëŠ” êµ¬(gu) í…ìŠ¤íŠ¸ í¬í•¨ ì—¬ë¶€ë¡œ ê°„ì´ ë§¤ì¹­
    kws = tokenize_korean_keywords(f"{main_taste} {main_purpose}")
    for p in extra_people:
        if (p.taste or "").strip() or (p.purpose or "").strip():
            kws.extend(tokenize_korean_keywords(f"{p.taste} {p.purpose}"))
    if extra_keywords:
        for k in extra_keywords:
            kws.extend(tokenize_korean_keywords(k))

    kws = list(dict.fromkeys(kws))  # unique

    if tour_spot_index and kws:
        gu = area.get("gu", "")
        rel_texts = tour_spot_index.get(gu, []) if gu else []

        # ë“±ì¥ íšŸìˆ˜ ê¸°ë°˜ ê°„ì´ ìŠ¤ì½”ì–´
        hit = 0
        for text in rel_texts[:300]:
            for k in kws:
                if k in text:
                    hit += 1
        base += min(6.0, hit * 0.15)

    # ì§€ì—­ë³„ ê¸°ë³¸ ì„±í–¥(í•˜ë“œì½”ë”©) ê°€ì (ì˜ˆì‹œ)
    vibe = {
        "ì¸ì‚¬ë™": ["ì „í†µ", "ë¬¸í™”", "ê³µì˜ˆ", "ì „ì‹œ"],
        "ì‚¼ì²­ë™": ["ì „í†µ", "ì¹´í˜", "ì‚°ì±…", "ì „ì‹œ"],
        "ì„œì´Œ": ["ì‚°ì±…", "ì¹´í˜", "ì „í†µ", "ì „ì‹œ"],
        "ìµì„ ë™": ["ë°ì´íŠ¸", "ë§›ì§‘", "ì¹´í˜", "í•œì˜¥"],
        "ì„±ìˆ˜": ["ì¹´í˜", "ì‡¼í•‘", "ì•¡í‹°ë¹„í‹°", "ì „ì‹œ"],
        "ì—°ë‚¨": ["ì¹´í˜", "ì‚°ì±…", "ë§›ì§‘", "ë°ì´íŠ¸"],
        "í•œë‚¨": ["ì˜ì „", "ë ˆìŠ¤í† ë‘", "ê°¤ëŸ¬ë¦¬", "ì‡¼í•‘"],
        "ì´íƒœì›": ["ì™¸êµ­ì¸", "ë‹¤êµ­ì ", "ë°”", "ë ˆìŠ¤í† ë‘"],
        "ì—¬ì˜ë„": ["ê°€ì¡±", "ì‡¼í•‘", "ê³µì—°", "ì‚°ì±…"],
        "ì ì‹¤": ["ê°€ì¡±", "ì‡¼í•‘", "ì•¡í‹°ë¹„í‹°", "ë°ì´íŠ¸"],
    }
    area_name_safe = area.get("area") or area.get("gu") or "ë¯¸ë¶„ë¥˜"
    area_tags = " ".join(vibe.get(area_name_safe, [])).lower()
    for k in tokenize_korean_keywords(f"{main_taste} {main_purpose}"):
        if k in area_tags:
            base += 0.8

    return float(base)


# -----------------------------
# Recommendation engine
# -----------------------------
def _ensure_place_id(p: Dict[str, Any]) -> str:
    pid = p.get("place_id")
    if pid:
        return str(pid)
    base = f"{p.get('name','')}|{p.get('address','')}"
    return hashlib.sha1(base.encode("utf-8")).hexdigest()


def _score_place(
    p: Dict[str, Any],
    user_tokens: List[str],
    extra_keywords: List[str],
) -> float:
    text = " ".join(
        [
            str(p.get("name", "")),
            " ".join(p.get("tags", []) if isinstance(p.get("tags"), list) else []),
            str(p.get("description", "")),
        ]
    ).lower()
    score = 0.0
    for k in user_tokens:
        if k and k in text:
            score += 0.4
    for k in extra_keywords:
        if k and k.lower() in text:
            score += 0.2
    return score


def build_master_pool(
    places: List[Dict[str, Any]],
    user_text: str,
    extra_keywords: List[str],
) -> List[Dict[str, Any]]:
    user_tokens = tokenize_korean_keywords(user_text)
    pool = []
    for p in places:
        # 'ë™' ê¸°ì¤€ ì¶”ì²œ: ë™ì´ ì—†ìœ¼ë©´ í›„ë³´ì—ì„œ ì œì™¸
        name = (p.get("name") or "").strip()
        address = (p.get("address") or "").strip()
        if is_excluded_place(name, address):
            continue
        dong = extract_dong_from_place(p)
        if not dong:
            continue
        if not is_korean_text(dong):
            continue
        if name and not is_korean_text(name):
            continue
        item = dict(p)
        item["place_id"] = _ensure_place_id(item)
        item["area"] = dong
        lat = p.get("lat")
        lng = p.get("lng")
        if isinstance(lat, (int, float)) and isinstance(lng, (int, float)):
            item["center"] = (lat, lng)
        else:
            item["center"] = (37.5665, 126.9780)
        item["score"] = _score_place(item, user_tokens, extra_keywords)
        pool.append(item)

    seed_base = abs(hash(user_text)) % 10000
    rng = random.Random(seed_base)
    for item in pool:
        item["score"] += rng.random() * 0.01

    pool.sort(key=lambda x: x["score"], reverse=True)
    return pool


def get_recommendations_from_places(
    places: List[Dict[str, Any]],
    signature: str,
    main_taste: str,
    main_purpose: str,
    crowd_pref: str,
    people: List[PersonInput],
    openai_api_key: str = "",
    refill_step: int = 50,
    base_limit: int = 200,
    max_limit: int = 500,
) -> List[Dict[str, Any]]:
    if not places:
        logger.warning("no places available; returning empty recommendations")
        return []

    extra_people = [p for p in people if not p.is_me]
    extra_keywords = expand_keywords_with_openai(openai_api_key, main_taste, main_purpose, extra_people)

    user_text = " ".join(
        [
            main_taste or "",
            main_purpose or "",
            " ".join([p.taste or "" for p in extra_people]),
            " ".join([p.purpose or "" for p in extra_people]),
        ]
    )

    # reset if signature changed
    if st.session_state.get("reco_signature") != signature:
        st.session_state.reco_signature = signature
        st.session_state.seen_place_ids = set()
        st.session_state.feed_buffer = []
        st.session_state.master_pool = build_master_pool(places, user_text, extra_keywords)
        st.session_state.cursor = 0
        st.session_state.pool_limit = base_limit

    master_pool = st.session_state.master_pool
    logger.info("master pool size=%d", len(master_pool))
    logger.info(
        "places=%d name_nonempty=%d gu_nonempty=%d",
        len(places),
        len([p for p in places if p.get("name")]),
        len([p for p in places if p.get("gu")]),
    )

    def refill():
        limit = min(st.session_state.pool_limit, len(master_pool))
        before = len(st.session_state.feed_buffer)
        while st.session_state.cursor < limit and len(st.session_state.feed_buffer) < limit:
            st.session_state.feed_buffer.append(master_pool[st.session_state.cursor])
            st.session_state.cursor += 1
        logger.info(
            "buffer refill: limit=%d cursor=%d size_before=%d size_after=%d",
            limit,
            st.session_state.cursor,
            before,
            len(st.session_state.feed_buffer),
        )

    def take(count: int) -> List[Dict[str, Any]]:
        results = []
        seen_areas: set = set()
        before = len(st.session_state.feed_buffer)
        while st.session_state.feed_buffer and len(results) < count:
            item = st.session_state.feed_buffer.pop(0)
            pid = item.get("place_id")
            if pid in st.session_state.seen_place_ids:
                continue
            area_name = item.get("area") or ""
            if area_name and area_name in seen_areas:
                continue
            st.session_state.seen_place_ids.add(pid)
            if area_name:
                seen_areas.add(area_name)
            results.append(item)
        logger.info("buffer take: before=%d after=%d returned=%d", before, len(st.session_state.feed_buffer), len(results))
        return results

    refill()
    results = take(RECOMMEND_COUNT)

    # relaxation: expand pool_limit and refill
    if len(results) < RECOMMEND_COUNT:
        st.session_state.pool_limit = min(max_limit, len(master_pool))
        refill()
        results += take(RECOMMEND_COUNT - len(results))

    if len(results) < RECOMMEND_COUNT:
        st.session_state.pool_limit = len(master_pool)
        refill()
        results += take(RECOMMEND_COUNT - len(results))

    # final top-up: allow duplicates (seen_place_ids ìœ ì§€) if still short
    if len(results) < RECOMMEND_COUNT:
        logger.warning("topup relaxation: allowing duplicates to fill")
        for item in master_pool:
            if len(results) >= RECOMMEND_COUNT:
                break
            results.append(item)

    # ê²½ê³ : ì–¸ì–´ì½”ë“œ í˜•íƒœ name ê²€ì¶œ
    def is_language_code(s: str) -> bool:
        if not s:
            return False
        s = s.strip()
        if re.fullmatch(r"[a-z]{2,3}$", s):
            return True
        if re.fullmatch(r"[a-z]{2,3}(-[A-Za-z0-9]{2,8})+$", s):
            return True
        if len(s) <= 3 and re.fullmatch(r"[A-Za-z]+", s):
            return True
        return False
    bad = [r.get("name") for r in results if is_language_code(str(r.get("name", "")))]
    if bad:
        logger.warning("language-code names in results: %s", bad)

    logger.info("returned=%d ids=%s", len(results), [r.get("place_id") for r in results])
    return results


# -----------------------------
# UI Components
# -----------------------------
def header_ui():
    st.markdown(
        f"""
        <style>
          @import url('https://fonts.googleapis.com/css2?family=Noto+Sans+KR:wght@600;700;800&display=swap');
          .app-title-kr {{
            font-family: 'Noto Sans KR', 'Apple SD Gothic Neo', 'Malgun Gothic', sans-serif;
            font-size: 42px;
            font-weight: 800;
            line-height: 1.05;
            letter-spacing: -0.5px;
          }}
          .app-title-en {{
            font-family: 'Noto Sans KR', 'Apple SD Gothic Neo', 'Malgun Gothic', sans-serif;
            font-size: 18px;
            font-weight: 600;
            color: #666;
          }}
        </style>
        <div style="padding: 4px 0 14px 0; text-align: center;">
          <div class="app-title-kr">ğŸ™ï¸ {APP_NAME_KR} ğŸ™ï¸</div>
        </div>
        """,
        unsafe_allow_html=True
    )

def sidebar_keys_ui():
    st.sidebar.markdown("## API í‚¤")
    openai_key = st.sidebar.text_input("OpenAI API Key", type="password", value=os.getenv("OPENAI_API_KEY", ""))
    seoul_key = st.sidebar.text_input("ì„œìš¸ ì—´ë¦°ë°ì´í„°ê´‘ì¥ ì¸ì¦í‚¤", type="password", value=os.getenv("SEOUL_API_KEY", ""))
    photo_korea_key = st.sidebar.text_input(
        "í¬í† ì½”ë¦¬ì•„ Service Key",
        type="password",
        value=os.getenv("PHOTO_KOREA_API_KEY", ""),
    )
    st.sidebar.markdown("---")
    st.sidebar.markdown(
        """
        - OpenAI í‚¤: ì¹´ë“œ ë‚´ ì¶”ì²œ ì´ìœ /ì½”ìŠ¤ ë¬¸êµ¬ ìƒì„±ì— ì‚¬ìš©  
        - ì„œìš¸ ì—´ë¦°ë°ì´í„° í‚¤: ì‹¤ì‹œê°„ ì¸êµ¬/ê´€ê´‘ëª…ì†Œ ë°ì´í„° í˜¸ì¶œì— ì‚¬ìš©  
        - í¬í† ì½”ë¦¬ì•„ í‚¤: ì§€ì—­ ëŒ€í‘œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì‹œ ì‚¬ìš©  
        """
    )
    return openai_key, seoul_key, photo_korea_key


# -----------------------------
# Local region images / metadata
# -----------------------------
@st.cache_data(ttl=3600)
def load_regions_config(path: Path) -> List[Dict[str, Any]]:
    if not path.exists():
        return []
    try:
        with path.open("r", encoding="utf-8") as f:
            data = json.load(f)
        return data if isinstance(data, list) else []
    except Exception:
        return []


def _normalize_region_text(text: str) -> str:
    if not text:
        return ""
    text = re.sub(r"[^\w\sê°€-í£]", " ", text)
    text = re.sub(r"\s+", "", text).lower()
    return text


@st.cache_data(ttl=3600)
def build_region_index(regions: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    indexed = []
    for r in regions:
        if not isinstance(r, dict):
            continue
        name_ko = str(r.get("name_ko", "")).strip()
        keywords = r.get("keywords", [])
        if not isinstance(keywords, list):
            keywords = []
        indexed.append(
            {
                "id": str(r.get("id", "")).strip(),
                "name_ko": name_ko,
                "keywords": [str(k).strip() for k in keywords if str(k).strip()],
                "name_norm": _normalize_region_text(name_ko),
                "keywords_norm": [_normalize_region_text(str(k)) for k in keywords],
            }
        )
    return indexed


def match_region_id(area_name: str, indexed_regions: List[Dict[str, Any]]) -> str:
    if not area_name or not indexed_regions:
        return ""
    area_norm = _normalize_region_text(area_name)
    best_id = ""
    best_score = 0
    for r in indexed_regions:
        score = 0
        if area_norm and area_norm in r["name_norm"]:
            score = 2
        elif area_norm and any(area_norm == k for k in r["keywords_norm"]):
            score = 1
        if score > best_score and r["id"]:
            best_score = score
            best_id = r["id"]
    return best_id


def get_region_keywords(area_name: str, indexed_regions: List[Dict[str, Any]]) -> List[str]:
    region_id = match_region_id(area_name, indexed_regions)
    if not region_id:
        fallback_map = {
            "ì„±ìˆ˜": ["ì„œìš¸ìˆ²", "ëšì„¬", "ì„±ìˆ˜ë™", "ì„±ìˆ˜ë™ ì¹´í˜ê±°ë¦¬", "ëšì„¬í•œê°•ê³µì›"],
            "ì ì‹¤": ["ë¡¯ë°ì›”ë“œíƒ€ì›Œ", "ë¡¯ë°ì›”ë“œ", "ì„ì´Œí˜¸ìˆ˜", "ì˜¬ë¦¼í”½ê³µì›", "ì ì‹¤ì¢…í•©ìš´ë™ì¥"],
            "í•œë‚¨": ["í•œë‚¨ë™", "í•œê°•ì§„", "ë¦¬ì›€ë¯¸ìˆ ê´€", "ë¸”ë£¨ìŠ¤í€˜ì–´", "UNë¹Œë¦¬ì§€", "í•œë‚¨ì˜¤ê±°ë¦¬"],
        }
        return fallback_map.get(area_name, [])
    for r in indexed_regions:
        if r.get("id") == region_id:
            kws = r.get("keywords", [])
            return [k for k in kws if k]
    return []


def expand_dong_terms(terms: List[str]) -> List[str]:
    expanded: List[str] = []
    for t in terms:
        t = str(t).strip()
        if not t:
            continue
        expanded.append(t)
        # "ë™"ì´ ë¶™ì§€ ì•Šì€ í–‰ì •êµ¬/ì§€ëª…ì— ëŒ€í•´ ë™ ë¶™ì´ê¸°
        if not t.endswith("ë™") and len(t) >= 2:
            expanded.append(f"{t}ë™")
    # ì¤‘ë³µ ì œê±°
    seen = set()
    uniq = []
    for t in expanded:
        if t not in seen:
            seen.add(t)
            uniq.append(t)
    return uniq


def get_nearby_keywords(area_name: str, indexed_regions: List[Dict[str, Any]]) -> List[str]:
    nearby = NEARBY_BEST.get(area_name, [])
    if not nearby:
        return []
    keywords = []
    for n in nearby:
        keywords.append(n)
        region_kws = get_region_keywords(n, indexed_regions)
        keywords.extend(region_kws)
    # ì¤‘ë³µ ì œê±°
    seen = set()
    uniq = []
    for k in keywords:
        k = str(k).strip()
        if k and k not in seen:
            seen.add(k)
            uniq.append(k)
    return uniq


@st.cache_data(ttl=3600)
def load_regions_meta(path: Path) -> Dict[str, Any]:
    if not path.exists():
        return {}
    try:
        with path.open("r", encoding="utf-8") as f:
            data = json.load(f)
        return data if isinstance(data, dict) else {}
    except Exception:
        return {}


def resolve_region_image_url(
    area_name: str,
    indexed_regions: List[Dict[str, Any]],
    regions_meta: Dict[str, Any],
) -> Tuple[str, str]:
    region_id = match_region_id(area_name, indexed_regions)
    if region_id:
        meta = regions_meta.get(region_id, {})
        url = str(
            meta.get("origin_url")
            or meta.get("image_url")
            or meta.get("url")
            or ""
        ).strip()
        if url.startswith("http://"):
            url = "https://" + url[len("http://"):]
        if url:
            return url, region_id
    return "", ""


@st.cache_data(ttl=3600)
def fetch_photo_korea_image_url(
    api_key: str,
    keyword: str,
    avoid_urls: Tuple[str, ...] = (),
    required_terms: Tuple[str, ...] = (),
    required_city: str = "ì„œìš¸",
) -> Dict[str, Any]:
    """
    í¬í† ì½”ë¦¬ì•„ APIì—ì„œ keywordë¡œ ëŒ€í‘œ ì´ë¯¸ì§€ URL/ìº¡ì…˜/ì´¬ì˜ì ì •ë³´ë¥¼ 1ê±´ ê°€ì ¸ì˜¨ë‹¤.
    TODO: í¬í† ì½”ë¦¬ì•„ OpenAPI ë¬¸ì„œì— ë§ì¶° ì—”ë“œí¬ì¸íŠ¸/íŒŒë¼ë¯¸í„°ë¥¼ ì¡°ì •í•˜ì„¸ìš”.
    """
    if not api_key or not keyword:
        return {}

    url = "https://apis.data.go.kr/B551011/PhotoGalleryService1/gallerySearchList1"
    params = {
        "serviceKey": api_key,
        "numOfRows": 10,
        "pageNo": 1,
        "MobileOS": "ETC",
        "MobileApp": "SeoulNomads",
        "_type": "json",
        "keyword": keyword,
    }

    def parse_int(v: Any) -> int:
        try:
            return int(str(v).strip())
        except Exception:
            return 0

    def pick_first_item(items: List[Dict[str, Any]]) -> Dict[str, Any]:
        if not items:
            return {}
        scored = []
        landscape_items = []
        for it in items:
            image_url = (
                it.get("galWebImageUrl")
                or it.get("galWebImageUrl1")
                or it.get("galWebImageUrl2")
                or it.get("originImgUrl")
                or it.get("imageUrl")
                or ""
            )
            if image_url in avoid_urls:
                continue
            title = str(it.get("galTitle", "") or it.get("title", ""))
            loc = str(it.get("galPhotographyLocation", "") or it.get("location", ""))
            addr = str(it.get("addr") or it.get("address") or it.get("galPhotographyLocation") or "")
            w = parse_int(it.get("galWebImageWidth") or it.get("imageWidth") or it.get("width"))
            h = parse_int(it.get("galWebImageHeight") or it.get("imageHeight") or it.get("height"))
            text = f"{title} {loc} {addr}"
            if required_city and required_city not in text:
                continue
            if required_terms:
                if not any(term in text for term in required_terms):
                    continue
            is_seoul = 1 if "ì„œìš¸" in text else 0
            is_landscape = 1 if w and h and w >= h else 0
            # í’ê²½/ì „ê²½/ì „ë§ ê°™ì€ í‚¤ì›Œë“œ ê°€ì 
            scenic = 1 if any(k in text for k in ["í’ê²½", "ì „ê²½", "ì „ë§", "ì•¼ê²½"]) else 0
            # 4:3ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ê°€ì 
            ratio_score = 0
            if w and h:
                ratio = w / h
                ratio_score = -abs(ratio - (4 / 3))
            scored.append((is_seoul, scenic, is_landscape, ratio_score, it))
            if is_landscape:
                landscape_items.append((is_seoul, scenic, ratio_score, it))

        if landscape_items:
            landscape_items.sort(key=lambda x: (x[0], x[1], x[2]), reverse=True)
            return landscape_items[0][3]

        scored.sort(key=lambda x: (x[0], x[1], x[2], x[3]), reverse=True)
        return scored[0][4]

    try:
        r = requests.get(url, params=params, timeout=15)
        r.raise_for_status()
        try:
            data = r.json()
            items = data.get("response", {}).get("body", {}).get("items", {}).get("item", [])
            if isinstance(items, dict):
                items = [items]
            item = pick_first_item(items)
        except Exception:
            # XML fallback
            import xml.etree.ElementTree as ET
            root = ET.fromstring(r.text)
            items = []
            for elem in root.iter():
                if elem.tag.lower().endswith("item"):
                    item = {}
                    for child in list(elem):
                        item[child.tag] = child.text or ""
                    if item:
                        items.append(item)
            item = pick_first_item(items)

        if not item:
            return {}

        image_url = (
            item.get("galWebImageUrl")
            or item.get("galWebImageUrl1")
            or item.get("galWebImageUrl2")
            or item.get("originImgUrl")
            or item.get("imageUrl")
            or ""
        )
        title = item.get("galTitle") or ""
        location = item.get("galPhotographyLocation") or ""
        photographer = item.get("galPhotographer") or item.get("photographer") or ""
        width = parse_int(item.get("galWebImageWidth") or item.get("imageWidth") or item.get("width"))
        height = parse_int(item.get("galWebImageHeight") or item.get("imageHeight") or item.get("height"))

        if isinstance(image_url, str) and image_url.startswith("http://"):
            image_url = "https://" + image_url[len("http://"):]

        caption = title or location or f"{keyword} í’ê²½"
        credit = "â“’í•œêµ­ê´€ê´‘ê³µì‚¬ ì‚¬ì§„ê°¤ëŸ¬ë¦¬"
        if photographer:
            credit = f"â“’í•œêµ­ê´€ê´‘ê³µì‚¬ ì‚¬ì§„ê°¤ëŸ¬ë¦¬-{photographer}"

        orientation = "unknown"
        if width and height:
            orientation = "landscape" if width >= height else "portrait"

        return {
            "url": image_url,
            "caption": caption,
            "credit": credit,
            "orientation": orientation,
        }
    except Exception:
        return {}


def get_image_and_meta(
    area_name: str,
    indexed_regions: List[Dict[str, Any]],
    regions_meta: Dict[str, Any],
    photo_korea_key: str,
    used_urls: set,
) -> Tuple[str, str, str, str]:
    img_url, region_id = resolve_region_image_url(area_name, indexed_regions, regions_meta)
    if img_url:
        meta = regions_meta.get(region_id, {}) if region_id else {}
        caption = meta.get("caption") or meta.get("title") or f"{area_name} í’ê²½"
        credit = meta.get("credit") or "â“’í•œêµ­ê´€ê´‘ê³µì‚¬ ì‚¬ì§„ê°¤ëŸ¬ë¦¬"
        return img_url, caption, credit, "unknown"

    # 1ì°¨: ì§€ì—­ëª…/í™•ì¥ í‚¤ì›Œë“œë¡œ "ì—„ê²© ë§¤ì¹­" ì‹œë„
    avoid = tuple(used_urls)
    region_keywords = get_region_keywords(area_name, indexed_regions)
    search_terms = expand_dong_terms([area_name] + region_keywords)
    required_terms = tuple(search_terms)

    fallback = fetch_photo_korea_image_url(
        photo_korea_key,
        f"ì„œìš¸ {area_name} í’ê²½",
        avoid_urls=avoid,
        required_terms=required_terms,
        required_city="ì„œìš¸",
    )
    if fallback.get("url"):
        return (
            fallback.get("url", ""),
            fallback.get("caption", f"{area_name} í’ê²½"),
            fallback.get("credit", "â“’í•œêµ­ê´€ê´‘ê³µì‚¬ ì‚¬ì§„ê°¤ëŸ¬ë¦¬"),
            fallback.get("orientation", "unknown"),
        )

    for kw in search_terms:
        if not kw:
            continue
        fallback = fetch_photo_korea_image_url(
            photo_korea_key,
            f"ì„œìš¸ {kw} í’ê²½",
            avoid_urls=avoid,
            required_terms=required_terms,
            required_city="ì„œìš¸",
        )
        if fallback.get("url"):
            return (
                fallback.get("url", ""),
                fallback.get("caption", f"{area_name} í’ê²½"),
                fallback.get("credit", "â“’í•œêµ­ê´€ê´‘ê³µì‚¬ ì‚¬ì§„ê°¤ëŸ¬ë¦¬"),
                fallback.get("orientation", "unknown"),
            )

    # 2ì°¨: ì—„ê²© ë§¤ì¹­ ì‹¤íŒ¨ ì‹œ, ë™ì¼ í‚¤ì›Œë“œë¡œ ì™„í™” ì¬ì‹œë„(ê·¸ë˜ë„ ê´€ë ¨ì„± ë†’ì€ ê²ƒ ìš°ì„ )
    fallback = fetch_photo_korea_image_url(
        photo_korea_key,
        f"ì„œìš¸ {area_name} í’ê²½",
        avoid_urls=avoid,
        required_terms=(),
        required_city="ì„œìš¸",
    )
    if fallback.get("url"):
        return (
            fallback.get("url", ""),
            fallback.get("caption", f"{area_name} í’ê²½"),
            fallback.get("credit", "â“’í•œêµ­ê´€ê´‘ê³µì‚¬ ì‚¬ì§„ê°¤ëŸ¬ë¦¬"),
            fallback.get("orientation", "unknown"),
        )

    for kw in search_terms:
        if not kw:
            continue
        fallback = fetch_photo_korea_image_url(
            photo_korea_key,
            f"ì„œìš¸ {kw} í’ê²½",
            avoid_urls=avoid,
            required_terms=(),
            required_city="ì„œìš¸",
        )
        if fallback.get("url"):
            return (
                fallback.get("url", ""),
                fallback.get("caption", f"{area_name} í’ê²½"),
                fallback.get("credit", "â“’í•œêµ­ê´€ê´‘ê³µì‚¬ ì‚¬ì§„ê°¤ëŸ¬ë¦¬"),
                fallback.get("orientation", "unknown"),
            )

    # 3ì°¨: "í’ê²½" ì—†ì´ë„ ê²€ìƒ‰ (ì¼ë¶€ í‚¤ì›Œë“œëŠ” í’ê²½ê³¼ ê°™ì´ ê²€ìƒ‰ ì‹œ ê²°ê³¼ê°€ ì¤„ì–´ë“¦)
    fallback = fetch_photo_korea_image_url(
        photo_korea_key,
        f"ì„œìš¸ {area_name}",
        avoid_urls=avoid,
        required_terms=(),
        required_city="ì„œìš¸",
    )
    if fallback.get("url"):
        return (
            fallback.get("url", ""),
            fallback.get("caption", f"{area_name} í’ê²½"),
            fallback.get("credit", "â“’í•œêµ­ê´€ê´‘ê³µì‚¬ ì‚¬ì§„ê°¤ëŸ¬ë¦¬"),
            fallback.get("orientation", "unknown"),
        )

    for kw in search_terms:
        if not kw:
            continue
        fallback = fetch_photo_korea_image_url(
            photo_korea_key,
            f"ì„œìš¸ {kw}",
            avoid_urls=avoid,
            required_terms=(),
            required_city="ì„œìš¸",
        )
        if fallback.get("url"):
            return (
                fallback.get("url", ""),
                fallback.get("caption", f"{area_name} í’ê²½"),
                fallback.get("credit", "â“’í•œêµ­ê´€ê´‘ê³µì‚¬ ì‚¬ì§„ê°¤ëŸ¬ë¦¬"),
                fallback.get("orientation", "unknown"),
            )

    # ì¸ê·¼ ì§€ì—­ í‚¤ì›Œë“œ fallbackì€ ì •í™•ë„ ì €í•˜ ê°€ëŠ¥ì„±ì´ ìˆì–´ ê¸°ë³¸ì ìœ¼ë¡œ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ

    return "", f"{area_name} í’ê²½", "â“’í•œêµ­ê´€ê´‘ê³µì‚¬ ì‚¬ì§„ê°¤ëŸ¬ë¦¬", "unknown"


def render_region_card(
    area_name: str,
    crowd_label: str,
    image_url: str,
    orientation: str = "unknown",
    height_px: int = 300,
):
    color = CROWD_COLOR.get(crowd_label, "gray")
    # ì¸ë¼ì¸ SVG placeholder (ë””ì½”ë” ì˜ì¡´ ì—†ì´ ì‚¬ìš©)
    svg_placeholder = (
        "data:image/svg+xml;utf8,"
        "<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 800 600'>"
        "<defs><linearGradient id='g' x1='0' x2='1' y1='0' y2='1'>"
        "<stop offset='0%' stop-color='%23f2f2f2'/>"
        "<stop offset='100%' stop-color='%23e6e6e6'/>"
        "</linearGradient></defs>"
        "<rect width='800' height='600' fill='url(%23g)'/>"
        "<text x='50%' y='50%' dominant-baseline='middle' text-anchor='middle' "
        "fill='%23999' font-size='28' font-family='sans-serif'>"
        "Image Unavailable</text>"
        "</svg>"
    )
    if image_url:
        # 4:3 ë¹„ìœ¨ ì¹´ë“œë¡œ ê°•ì œ (ê°€ë¡œí˜• ìš°ì„ )
        safe_url = image_url.replace("'", "%27")
        fit = "cover" if orientation != "portrait" else "contain"
        html = f"""
        <div style="position:relative; border-radius:16px; overflow:hidden; border:1px solid #e6e6e6;">
          <img src="{safe_url}" onerror="this.onerror=null;this.src='{svg_placeholder}';"
               style="width:100%; height:{height_px}px; object-fit:{fit}; display:block; background:#f2f2f2;">
          <div style="position:absolute; top:10px; left:10px;
                      padding:6px 10px; border-radius:8px; background:white;
                      font-weight:700; border:1px solid #e0e0e0; color:{color};">
            {crowd_label}
          </div>
          <div style="position:absolute; bottom:10px; left:10px;
                      padding:6px 10px; border-radius:8px; background:rgba(0,0,0,0.55);
                      color:white; font-weight:700;">
            {area_name}
          </div>
        </div>
        """
        st.markdown(html, unsafe_allow_html=True)
        return

    # ì´ë¯¸ì§€ URLì´ ì—†ìœ¼ë©´ HTML ì¹´ë“œë¡œ fallback (Streamlit ë””ì½”ë” ì‚¬ìš© ì•ˆ í•¨)
    html = f"""
    <div style="position:relative; border-radius:16px; overflow:hidden; border:1px solid #e6e6e6;
                background:linear-gradient(135deg,#f2f2f2,#e8e8e8); height:{height_px}px;">
      <div style="position:absolute; top:10px; left:10px;
                  padding:6px 10px; border-radius:8px; background:white;
                  font-weight:700; border:1px solid #e0e0e0; color:{color};">
        {crowd_label}
      </div>
      <div style="position:absolute; bottom:10px; left:10px;
                  padding:6px 10px; border-radius:8px; background:rgba(0,0,0,0.55);
                  color:white; font-weight:700;">
        {area_name}
      </div>
    </div>
    """
    st.markdown(html, unsafe_allow_html=True)

def crowd_slider_ui() -> str:
    return st.select_slider(
        "í˜¼ì¡ë„",
        options=CROWD_LEVELS,
        value=CROWD_LEVELS[1],
        label_visibility="collapsed",
    )

def parse_taste_purpose(raw: str) -> Tuple[str, str]:
    if not raw:
        return "", ""

    text = raw.strip()
    taste = ""
    purpose = ""

    # "ì·¨í–¥: ..." / "ëª©ì : ..." í˜•ì‹ ìš°ì„  íŒŒì‹±
    mt = re.search(r"ì·¨í–¥\s*[:\-]\s*(.+)", text)
    mp = re.search(r"ëª©ì \s*[:\-]\s*(.+)", text)
    if mt:
        taste = mt.group(1).splitlines()[0].strip()
    if mp:
        purpose = mp.group(1).splitlines()[0].strip()
    if taste or purpose:
        return taste, purpose

    # êµ¬ë¶„ì ê¸°ë°˜ íŒŒì‹±
    if "/" in text:
        parts = [p.strip() for p in text.split("/", 1)]
        taste = parts[0]
        purpose = parts[1] if len(parts) > 1 else ""
        return taste, purpose

    # ì¤„ë°”ê¿ˆ ê¸°ë°˜ íŒŒì‹±
    lines = [l.strip() for l in text.splitlines() if l.strip()]
    if len(lines) >= 2:
        return lines[0], lines[1]

    return text, ""

def location_ui(prefix: str, default_scope: str = "ì„œìš¸ ë‚´") -> StartLocation:
    scope = st.radio(
        "ì¶œë°œ ì§€ì—­",
        options=["ì„œìš¸ ë‚´", "ì„œìš¸ ì™¸ë¶€"],
        horizontal=True,
        index=0 if default_scope == "ì„œìš¸ ë‚´" else 1,
        key=f"{prefix}_scope",
        label_visibility="collapsed",
    )

    if scope == "ì„œìš¸ ë‚´":
        gu = st.text_input(
            "êµ¬",
            key=f"{prefix}_gu",
            placeholder="êµ¬",
            label_visibility="collapsed",
        )
        dong = st.text_input(
            "ë™",
            key=f"{prefix}_dong",
            placeholder="ë™",
            label_visibility="collapsed",
        )
        return StartLocation(scope=scope, gu=gu, dong=dong, si="")
    else:
        si = st.text_input(
            "ì‹œ",
            key=f"{prefix}_si",
            placeholder="ì‹œ",
            label_visibility="collapsed",
        )
        dong = st.text_input(
            "ë™",
            key=f"{prefix}_dong_out",
            placeholder="ë™",
            label_visibility="collapsed",
        )
        return StartLocation(scope=scope, si=si, dong=dong, gu="")

def person_block_ui(i: int, person: PersonInput):
    st.markdown("#### ê´€ê³„")
    person.relationship = st.text_input(
        "ê´€ê³„",
        value=person.relationship,
        key=f"p{i}_rel",
        placeholder="ê´€ê³„",
        label_visibility="collapsed",
    )
    st.markdown("#### ì·¨í–¥ê³¼ ëª©ì ")
    combined = ""
    if person.taste or person.purpose:
        lines = []
        if person.taste:
            lines.append(f"ì·¨í–¥: {person.taste}")
        if person.purpose:
            lines.append(f"ëª©ì : {person.purpose}")
        combined = "\n".join(lines)
    raw = st.text_area(
        "ì·¨í–¥ê³¼ ëª©ì  (ììœ ì…ë ¥)",
        value=combined,
        height=110,
        key=f"p{i}_taste_purpose",
        placeholder="ì·¨í–¥ê³¼ ëª©ì  (ììœ ì…ë ¥)",
        label_visibility="collapsed",
    )
    person.taste, person.purpose = parse_taste_purpose(raw)
    st.markdown("#### ì¶œë°œ ì§€ì—­")
    loc = location_ui(prefix=f"p{i}_", default_scope=person.start_location.scope)
    person.start_location = loc

def naver_map_link(area_name: str) -> str:
    # URL ì§ì ‘ ë…¸ì¶œ ìš”êµ¬ê°€ ìˆì–´ ê·¸ëŒ€ë¡œ êµ¬ì„±
    return f"https://map.naver.com/v5/search/{requests.utils.quote(area_name)}"

def kakao_map_link(area_name: str) -> str:
    return f"https://map.kakao.com/?q={requests.utils.quote(area_name)}"

def google_map_link(area_name: str) -> str:
    return f"https://www.google.com/maps/search/?api=1&query={requests.utils.quote(area_name)}"

def render_map(area_center: Tuple[float, float], label: str, height_px: int = 300):
    lat, lon = area_center
    deck = pdk.Deck(
        map_style="https://basemaps.cartocdn.com/gl/positron-gl-style/style.json",
        initial_view_state=pdk.ViewState(latitude=lat, longitude=lon, zoom=12, pitch=0),
        layers=[
            pdk.Layer(
                "ScatterplotLayer",
                data=[{"lat": lat, "lon": lon, "name": label}],
                get_position="[lon, lat]",
                get_radius=200,
                get_fill_color="[255, 0, 0, 180]",
                pickable=True,
            ),
            pdk.Layer(
                "TextLayer",
                data=[{"lat": lat, "lon": lon, "name": label}],
                get_position="[lon, lat]",
                get_text="name",
                get_size=22,
                get_color="[0, 0, 0, 230]",
                get_text_anchor="middle",
                get_alignment_baseline="bottom",
                pickable=False,
            ),
        ],
        tooltip={"text": "{name}"}
    )
    st.pydeck_chart(deck, use_container_width=True, height=height_px)
    st.markdown(
        "<div style='text-align:center; font-size:12px; color:#666;'>"
        "ì§€ë„ë¥¼ í™•ëŒ€/ì´ë™í•˜ë©´ ì£¼ë³€ ì§€ì—­ë„ í•¨ê»˜ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        "</div>",
        unsafe_allow_html=True,
    )

def crowd_badge(label: str, title: str = "ì‹¤ì‹œê°„ í˜¼ì¡ë„"):
    color = CROWD_COLOR.get(label, "gray")
    st.markdown(
        f"""
        <div style="display:inline-block; padding:6px 10px; border-radius:8px;
             border:1px solid #ddd; font-weight:700; color:{color};">
          {title}: {label}
        </div>
        """,
        unsafe_allow_html=True
    )


# -----------------------------
# Transit time estimation (heuristic)
# -----------------------------
def estimate_travel_time(start: StartLocation, area: Dict[str, Any]) -> Tuple[int, str]:
    """
    ê°„ì´ ì¶”ì •:
    - ê°™ì€ êµ¬: 20~30ë¶„ (ì§€í•˜ì² )
    - ë‹¤ë¥¸ êµ¬(ì„œìš¸ ë‚´): 40~60ë¶„ (ì§€í•˜ì² )
    - ì„œìš¸ ì™¸ë¶€: 70~100ë¶„ (ì§€í•˜ì² /ë²„ìŠ¤)
    """
    if not start:
        return 0, ""

    area_gu = area.get("gu", "")
    area_name = area.get("area", "")

    if start.scope == "ì„œìš¸ ì™¸ë¶€":
        return 90, "ì§€í•˜ì² /ë²„ìŠ¤"

    # ì„œìš¸ ë‚´
    if start.gu and area_gu and start.gu.strip() == area_gu.strip():
        return 25, "ì§€í•˜ì² "

    if start.dong and area_name and area_name in start.dong:
        return 15, "ì§€í•˜ì² "

    if start.gu:
        return 50, "ì§€í•˜ì² "

    return 55, "ì§€í•˜ì² "


def build_travel_time_lines(people: List[PersonInput], area: Dict[str, Any]) -> List[str]:
    lines: List[str] = []
    for idx, p in enumerate(people):
        loc = p.start_location
        if not loc:
            continue
        # ìµœì†Œí•œ êµ¬/ë™/ì‹œ ì •ë³´ê°€ ìˆì„ ë•Œë§Œ í‘œê¸°
        if not (loc.gu or loc.dong or loc.si):
            continue
        mins, mode = estimate_travel_time(loc, area)
        if mins <= 0:
            continue
        label = "ë³¸ì¸" if p.is_me else (p.relationship or f"ë™í–‰ì {idx}")
        lines.append(f"{label}: ì•½ {mins}ë¶„ ({mode})")
    return lines


def haversine_km(a: Tuple[float, float], b: Tuple[float, float]) -> float:
    lat1, lon1 = a
    lat2, lon2 = b
    r = 6371.0
    p1 = math.radians(lat1)
    p2 = math.radians(lat2)
    dlat = math.radians(lat2 - lat1)
    dlon = math.radians(lon2 - lon1)
    s = math.sin(dlat / 2) ** 2 + math.cos(p1) * math.cos(p2) * math.sin(dlon / 2) ** 2
    c = 2 * math.atan2(math.sqrt(s), math.sqrt(1 - s))
    return r * c


def estimate_start_center(places: List[Dict[str, Any]], start: StartLocation) -> Optional[Tuple[float, float]]:
    if not start:
        return None
    key = (start.dong or "").strip()
    if key:
        matches = [
            p for p in places
            if isinstance(p.get("lat"), (int, float))
            and isinstance(p.get("lng"), (int, float))
            and key in str(p.get("address", ""))
        ]
    else:
        gu = (start.gu or "").strip()
        matches = [
            p for p in places
            if isinstance(p.get("lat"), (int, float))
            and isinstance(p.get("lng"), (int, float))
            and gu
            and gu in str(p.get("address", ""))
        ]
    if not matches:
        return None
    lats = [p["lat"] for p in matches]
    lngs = [p["lng"] for p in matches]
    return (sum(lats) / len(lats), sum(lngs) / len(lngs))


def build_distance_lines(people: List[PersonInput], area: Dict[str, Any], places_pool: List[Dict[str, Any]]) -> List[str]:
    lines: List[str] = []
    dest = area.get("center")
    if not dest:
        return lines
    for idx, p in enumerate(people):
        label = "ë³¸ì¸" if p.is_me else (p.relationship or f"ë™í–‰ì {idx}")
        start_center = estimate_start_center(places_pool, p.start_location)
        if not start_center:
            continue
        km = haversine_km(start_center, dest)
        lines.append(f"{label}: ì•½ {km:.1f}km")
    return lines


@st.cache_data(ttl=3600)
def get_nearby_stations_openai(
    openai_api_key: str,
    area_name: str,
    address: str,
) -> List[str]:
    if not openai_api_key:
        return []
    url = "https://api.openai.com/v1/chat/completions"
    headers = {
        "Authorization": f"Bearer {openai_api_key}",
        "Content-Type": "application/json",
    }
    sys = "ì„œìš¸ ì§€í•˜ì² ì—­ ì¶”ì²œê¸°. JSONë§Œ ë°˜í™˜."
    user = {
        "place": area_name,
        "address": address,
        "format": {"stations": ["string", "string", "string"]},
    }
    payload = {
        "model": "gpt-4o-mini",
        "messages": [
            {"role": "system", "content": sys},
            {"role": "user", "content": json.dumps(user, ensure_ascii=False)},
        ],
        "temperature": 0.3,
        "response_format": {"type": "json_object"},
    }
    try:
        resp = requests.post(url, headers=headers, json=payload, timeout=20)
        resp.raise_for_status()
        content = resp.json()["choices"][0]["message"]["content"]
        data = json.loads(content)
        stations = data.get("stations", [])
        if isinstance(stations, list):
            return [str(s).strip() for s in stations if str(s).strip()]
    except Exception:
        return []
    return []


@st.cache_data(ttl=3600)
def get_travel_times_openai(
    openai_api_key: str,
    area_name: str,
    address: str,
    people: List[PersonInput],
) -> List[str]:
    if not openai_api_key:
        return []
    url = "https://api.openai.com/v1/chat/completions"
    headers = {
        "Authorization": f"Bearer {openai_api_key}",
        "Content-Type": "application/json",
    }
    sys = "ëŒ€ì¤‘êµí†µ ì´ë™ì‹œê°„ ì¶”ì •ê¸°. JSONë§Œ ë°˜í™˜."
    user = {
        "destination": {"name": area_name, "address": address},
        "origins": [
            {
                "label": "ë³¸ì¸" if p.is_me else (p.relationship or "ë™í–‰ì"),
                "scope": p.start_location.scope,
                "si": p.start_location.si,
                "gu": p.start_location.gu,
                "dong": p.start_location.dong,
            }
            for p in people
        ],
        "format": {"times": [{"label": "string", "minutes": 0, "mode": "ì§€í•˜ì² /ë²„ìŠ¤"}]},
    }
    payload = {
        "model": "gpt-4o-mini",
        "messages": [
            {"role": "system", "content": sys},
            {"role": "user", "content": json.dumps(user, ensure_ascii=False)},
        ],
        "temperature": 0.2,
        "response_format": {"type": "json_object"},
    }
    try:
        resp = requests.post(url, headers=headers, json=payload, timeout=20)
        resp.raise_for_status()
        content = resp.json()["choices"][0]["message"]["content"]
        data = json.loads(content)
        times = data.get("times", [])
        lines = []
        if isinstance(times, list):
            for t in times:
                label = str(t.get("label", "")).strip()
                mins = t.get("minutes", None)
                mode = str(t.get("mode", "")).strip() or "ì§€í•˜ì² "
                if label and isinstance(mins, int):
                    lines.append(f"{label}: ì•½ {mins}ë¶„ ({mode})")
        return lines
    except Exception:
        return []


# -----------------------------
# Main App
# -----------------------------
def main():
    init_state()
    header_ui()
    openai_key, seoul_key, photo_korea_key = sidebar_keys_ui()

    regions_config = load_regions_config(REGIONS_JSON_PATH)
    indexed_regions = build_region_index(regions_config)
    regions_meta = load_regions_meta(REGIONS_META_PATH)

    # í•«ë§í¬ ëª¨ë“œì—ì„œëŠ” ë©”íƒ€ê°€ ë¹„ì–´ë„ ì•±ì´ ë™ì‘í•˜ë„ë¡ ê²½ê³ ë¥¼ ë„ìš°ì§€ ì•ŠìŒ

    if "view" not in st.session_state:
        st.session_state.view = "list"
    if "selected_area_name" not in st.session_state:
        st.session_state.selected_area_name = None
    if "used_image_urls" not in st.session_state:
        st.session_state.used_image_urls = set()

    # -------------------------
    # Main input area
    # -------------------------
    st.markdown("## ë‹¹ì‹ ì˜ ì¡°ê±´ê³¼ ì·¨í–¥")
    left_col, right_col = st.columns([0.62, 0.38], gap="large")

    with left_col:
        with st.form("main_form"):
            st.markdown("### ì·¨í–¥ê³¼ ëª©ì ")
            st.markdown(
                """
                <div style="display:inline-block; padding:8px 10px; border:1px solid #e0e0e0;
                            border-radius:8px; background:#f7f7f7; font-size:12px; color:#666; margin-bottom:8px;">
                  <div style="font-weight:600; margin-bottom:4px;">ì˜ˆì‹œ</div>
                  <div>ì·¨í–¥ - ë¯¸ì‹, ì‡¼í•‘, ì „í†µ, ì•¡í‹°ë¹„í‹°, ì¹´í˜íˆ¬ì–´, ìì—°</div>
                  <div>ëª©ì  - ë°ì´íŠ¸, ê°€ì¡±, ì˜ì „, í˜¼ìì—¬í–‰, ì¹œêµ¬ëª¨ì„, ê¸°ë…ì¼</div>
                </div>
                """,
                unsafe_allow_html=True,
            )
            main_text = st.text_area(
                "ì·¨í–¥ê³¼ ëª©ì  (ììœ ì…ë ¥)",
                height=140,
                key="main_taste_purpose",
                placeholder="ì·¨í–¥ê³¼ ëª©ì  (ììœ ì…ë ¥)",
                label_visibility="collapsed",
            )
            main_taste, main_purpose = parse_taste_purpose(main_text)

            st.markdown("### í˜¼ì¡ë„")
            crowd_pref = crowd_slider_ui()

            st.markdown("### ì¶œë°œ ì§€ì—­")
            main_loc = location_ui(prefix="main_", default_scope="ì„œìš¸ ë‚´")

            # ì¸ì› ê´€ë¦¬ ë²„íŠ¼ë“¤ì€ form ë°–ì—ì„œ ì²˜ë¦¬í•˜ëŠ” ê²Œ ì•ˆì •ì ì´ì§€ë§Œ,
            # UXë¥¼ ìœ„í•´ form ì•ˆì—ì„œë„ ë³´ì´ê²Œ í•˜ê³  ì‹¤ì œ ë™ì‘ì€ form ë°–ì—ì„œ ì²˜ë¦¬.

            # ë²„íŠ¼ ë°°ì¹˜: [ëª¨ë‘ ì¬ì¶”ì²œ] [ì¶”ì²œ ì‹¤í–‰] [ë¹„ì„ í˜¸ ì¬ì¶”ì²œ]
            b_left, b_center, b_right = st.columns([1, 1, 1])
            with b_center:
                run = st.form_submit_button("ì¶”ì²œ ì‹¤í–‰", use_container_width=True, type="primary")
            show_reco_buttons = bool(st.session_state.last_reco) or run
            with b_left:
                if show_reco_buttons:
                    rerank_all_clicked = st.form_submit_button("ëª¨ë‘ ì¬ì¶”ì²œ", use_container_width=True)
                else:
                    rerank_all_clicked = False
            with b_right:
                if show_reco_buttons:
                    rerank_dislike_clicked = st.form_submit_button("ë¹„ì„ í˜¸ ì¬ì¶”ì²œ", use_container_width=True)
                else:
                    rerank_dislike_clicked = False

        # form ë°”ê¹¥: ì¸ì› ì¶”ê°€/ì œê±° ì»¨íŠ¸ë¡¤
        c1, c2 = st.columns([0.5, 0.5])
        with c1:
            if st.button("ë™í–‰ì ì¶”ê°€", use_container_width=True, disabled=(len(st.session_state.people) >= 1 + MAX_EXTRA_PEOPLE)):
                if len(st.session_state.people) < 1 + MAX_EXTRA_PEOPLE:
                    st.session_state.people.append(default_person(is_me=False))
                    st.rerun()
        with c2:
            if st.button("ë™í–‰ì ì œê±°", use_container_width=True, disabled=(len(st.session_state.people) <= 1)):
                if len(st.session_state.people) > 1:
                    st.session_state.people.pop()
                    st.rerun()
        st.info("ë™í–‰ìëŠ” ìµœëŒ€ 2ëª…ê¹Œì§€ ì¶”ê°€ ê°€ëŠ¥í•˜ë©°, ê³µë€ìœ¼ë¡œ ë‘˜ ì‹œ ì¶”ì²œì— ë°˜ì˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.", icon=None)

    # ë™í–‰ì ì…ë ¥ UI (ì˜¤ë¥¸ìª½ ì˜ì—­)
    with right_col:
        if len(st.session_state.people) > 1:
            for idx in range(1, len(st.session_state.people)):
                st.markdown(f"### ë™í–‰ì {idx}")
                with st.container(border=True):
                    person_block_ui(idx, st.session_state.people[idx])

    # -------------------------
    # Recommendation logic + render
    # -------------------------
    if run:
        # ë©”ì¸ ì‚¬ìš©ì ì •ë³´ ì„¸ì…˜ ë°˜ì˜
        me = st.session_state.people[0]
        me.taste = main_taste
        me.purpose = main_purpose
        me.start_location = main_loc
        st.session_state.people[0] = me

        signature = make_signature(main_taste, main_purpose, crowd_pref, st.session_state.people)
        st.session_state.last_signature = signature

        # ë°ì´í„° fetch
        pop_raw = fetch_seoul_realtime_population(seoul_key)
        places = get_tour_places()
        assert all("area" in p for p in places), "area field missing in places"
        unique_gus = sorted({p.get("gu") for p in places if p.get("gu")})
        gu_list = tuple(sorted({p.get("gu", "") for p in places if p.get("gu")}))
        tour_spot_index = build_tour_spot_index(places, gu_list)
        with_coords = [p for p in places if isinstance(p.get("lat"), (int, float)) and isinstance(p.get("lng"), (int, float))]
        no_gu = [p for p in places if not p.get("gu")]
        name_empty = len([p for p in places if not p.get("name")])
        addr_empty = len([p for p in places if not p.get("address")])
        gu_empty = len([p for p in places if not p.get("gu")])
        logger.info("places=%d unique_gu=%d (%s)", len(places), len(unique_gus), unique_gus[:30])
        logger.info(
            "normalize empty ratios: name=%d addr=%d gu=%d",
            name_empty,
            addr_empty,
            gu_empty,
        )
        logger.info("places_with_coords=%d no_gu=%d", len(with_coords), len(no_gu))
        if places:
            sample = places[:5]
            logger.info(
                "sample places: %s",
                [
                    {
                        "name": s.get("name"),
                        "gu": s.get("gu"),
                        "lat": s.get("lat"),
                        "lng": s.get("lng"),
                        "address": s.get("address"),
                    }
                    for s in sample
                ],
            )
        logger.info("master pool init for signature=%s", signature)

        # ë””ë²„ê·¸: íˆ¬ì–´ ìŠ¤íŒŸ/í›„ë³´êµ° ê°œìˆ˜ í‘œì‹œ
        st.sidebar.caption(f"íˆ¬ì–´ ìŠ¤íŒŸ: {len(places)}ê°œ")

        recos = get_recommendations_from_places(
            places=places,
            signature=signature,
            main_taste=main_taste,
            main_purpose=main_purpose,
            crowd_pref=crowd_pref,
            people=st.session_state.people,
            openai_api_key=openai_key,
        )
        st.session_state.last_reco = recos

    def crowd_pref_from_ui(signature: str) -> str:
        # sliderëŠ” rerun ì‹œ main_formì—ì„œ ì„¤ì •ëœ ê°’ì„ ê°€ì ¸ì˜¤ê¸° ì–´ë µê¸° ë•Œë¬¸ì—
        # ê°€ì¥ ìµœê·¼ ì…ë ¥ê°’(ì„¸ì…˜ì— ë‚¨ì•„ìˆì„ ìˆ˜ ìˆìŒ)ì„ ìµœëŒ€í•œ ì‚¬ìš©
        # st.slider ê°’ keyê°€ ì—†ì–´ì„œ ì—¬ê¸°ì„  ì‚¬ìš©ì ì„ íƒì„ ë‹¤ì‹œ ì¶”ì • ë¶ˆê°€ â†’ last_signatureì— ì €ì¥ëœ crowdë¥¼ ì´ìš©
        try:
            sig = json.loads(signature)
            cp = sig.get("crowd_pref", "ì•½ê°„ ë¶ë¹”")
            if cp in CROWD_LEVELS:
                return cp
        except Exception:
            pass
        return "ì•½ê°„ ë¶ë¹”"

    def rerank_after_dislike(signature: str, selected_dislikes: List[str]):
        if not selected_dislikes:
            return

        disliked_set = st.session_state.disliked.get(signature, set())
        disliked_set.update(selected_dislikes)
        # place_id ê¸°ë°˜ ì œì™¸ë„ í•¨ê»˜ ë°˜ì˜
        for a in st.session_state.last_reco:
            if a.get("area") in selected_dislikes and a.get("place_id"):
                disliked_set.add(a.get("place_id"))
        st.session_state.disliked[signature] = disliked_set

        pop_raw = fetch_seoul_realtime_population(seoul_key)
        places = get_tour_places()
        assert all("area" in p for p in places), "area field missing in places"
        unique_gus = sorted({p.get("gu") for p in places if p.get("gu")})
        gu_list = tuple(sorted({p.get("gu", "") for p in places if p.get("gu")}))
        tour_spot_index = build_tour_spot_index(places, gu_list)
        with_coords = [p for p in places if isinstance(p.get("lat"), (int, float)) and isinstance(p.get("lng"), (int, float))]
        no_gu = [p for p in places if not p.get("gu")]
        name_empty = len([p for p in places if not p.get("name")])
        addr_empty = len([p for p in places if not p.get("address")])
        gu_empty = len([p for p in places if not p.get("gu")])
        logger.info("places=%d unique_gu=%d (%s)", len(places), len(unique_gus), unique_gus[:30])
        logger.info(
            "normalize empty ratios: name=%d addr=%d gu=%d",
            name_empty,
            addr_empty,
            gu_empty,
        )
        logger.info("places_with_coords=%d no_gu=%d", len(with_coords), len(no_gu))
        if places:
            sample = places[:5]
            logger.info(
                "sample places: %s",
                [
                    {
                        "name": s.get("name"),
                        "gu": s.get("gu"),
                        "lat": s.get("lat"),
                        "lng": s.get("lng"),
                        "address": s.get("address"),
                    }
                    for s in sample
                ],
            )
        logger.info("master pool reuse for signature=%s", signature)

        # ë””ë²„ê·¸: íˆ¬ì–´ ìŠ¤íŒŸ/í›„ë³´êµ° ê°œìˆ˜ í‘œì‹œ
        st.sidebar.caption(f"íˆ¬ì–´ ìŠ¤íŒŸ: {len(places)}ê°œ")

        new_recos = get_recommendations_from_places(
            places=places,
            signature=signature,
            main_taste=st.session_state.people[0].taste,
            main_purpose=st.session_state.people[0].purpose,
            crowd_pref=crowd_pref_from_ui(signature),
            people=st.session_state.people,
            openai_api_key=openai_key,
        )
        st.session_state.last_reco = new_recos

    def rerank_all_recos(signature: str):
        # í˜„ì¬ ì¶”ì²œ ê²°ê³¼ë¥¼ ë¹„ì„ í˜¸ë¡œ ì¶”ê°€í•˜ì—¬ ë™ì¼ ì§€ì—­ ì¬ë“±ì¥ ë°©ì§€
        current = st.session_state.last_reco or []
        if current:
            disliked_set = st.session_state.disliked.get(signature, set())
            for a in current:
                pid = a.get("place_id")
                if pid:
                    disliked_set.add(pid)
            st.session_state.disliked[signature] = disliked_set

        pop_raw = fetch_seoul_realtime_population(seoul_key)
        places = get_tour_places()
        assert all("area" in p for p in places), "area field missing in places"
        unique_gus = sorted({p.get("gu") for p in places if p.get("gu")})
        gu_list = tuple(sorted({p.get("gu", "") for p in places if p.get("gu")}))
        tour_spot_index = build_tour_spot_index(places, gu_list)
        with_coords = [p for p in places if isinstance(p.get("lat"), (int, float)) and isinstance(p.get("lng"), (int, float))]
        no_gu = [p for p in places if not p.get("gu")]
        name_empty = len([p for p in places if not p.get("name")])
        addr_empty = len([p for p in places if not p.get("address")])
        gu_empty = len([p for p in places if not p.get("gu")])
        logger.info("places=%d unique_gu=%d (%s)", len(places), len(unique_gus), unique_gus[:30])
        logger.info(
            "normalize empty ratios: name=%d addr=%d gu=%d",
            name_empty,
            addr_empty,
            gu_empty,
        )
        logger.info("places_with_coords=%d no_gu=%d", len(with_coords), len(no_gu))
        if places:
            sample = places[:5]
            logger.info(
                "sample places: %s",
                [
                    {
                        "name": s.get("name"),
                        "gu": s.get("gu"),
                        "lat": s.get("lat"),
                        "lng": s.get("lng"),
                        "address": s.get("address"),
                    }
                    for s in sample
                ],
            )
        logger.info("master pool reuse for signature=%s", signature)
        # ë””ë²„ê·¸: íˆ¬ì–´ ìŠ¤íŒŸ/í›„ë³´êµ° ê°œìˆ˜ í‘œì‹œ
        st.sidebar.caption(f"íˆ¬ì–´ ìŠ¤íŒŸ: {len(places)}ê°œ")

        new_recos = get_recommendations_from_places(
            places=places,
            signature=signature,
            main_taste=st.session_state.people[0].taste,
            main_purpose=st.session_state.people[0].purpose,
            crowd_pref=crowd_pref_from_ui(signature),
            people=st.session_state.people,
            openai_api_key=openai_key,
        )
        st.session_state.last_reco = new_recos

    # ê²°ê³¼ í™”ë©´: ì¶”ì²œ ì‹¤í–‰ ì‹œ ë©”ì¸ í™”ë©´ ì•„ë˜ ìƒì„±
    if st.session_state.last_reco:
        st.markdown("---")
        st.markdown("## ì¶”ì²œ ê²°ê³¼")

        signature = st.session_state.last_signature
        recos = st.session_state.last_reco

        if rerank_all_clicked:
            rerank_all_recos(signature)
            st.rerun()

        if rerank_dislike_clicked:
            disliked_set = st.session_state.disliked.get(signature, set())
            rerank_after_dislike(signature, list(disliked_set))
            st.rerun()

        if st.session_state.view == "list":
            st.session_state.used_image_urls = set()
            rows = [recos[i:i + 2] for i in range(0, len(recos), 2)]
            for row in rows:
                row_cols = st.columns(2, gap="large")
                for col, area in zip(row_cols, row):
                    area_name = area.get("area") or ""
                    if is_excluded_place(area.get("name") or "", area.get("addr") or area.get("address") or ""):
                        continue
                    if not area_name or not is_korean_text(area_name):
                        continue
                    crowd_now = area.get("crowd_now", "ì•½ê°„ ë¶ë¹”")
                    rank = recos.index(area) + 1

                    with col:
                        with st.container(border=True):
                            top_cols = st.columns([0.6, 0.4])
                            with top_cols[0]:
                                st.markdown(f"### ({rank}) {area_name}")
                            with top_cols[1]:
                                _spacer, _btn = st.columns([0.2, 0.8])
                                with _btn:
                                    if st.button("ìƒì„¸ ë³´ê¸°", key=f"detail_{rank}", type="primary"):
                                        st.session_state.selected_area_name = area_name
                                        st.session_state.view = "detail"
                                        st.rerun()

                            # 1) ëŒ€í‘œ ì´ë¯¸ì§€ (ë¡œì»¬ ì €ì¥ë³¸)
                            img_url, caption, credit, orientation = get_image_and_meta(
                                area_name,
                                indexed_regions,
                                regions_meta,
                                photo_korea_key,
                                st.session_state.used_image_urls,
                            )
                            if img_url:
                                st.session_state.used_image_urls.add(img_url)
                            render_region_card(area_name, crowd_now, img_url, orientation, height_px=280)
                            st.markdown(
                                f"<div style='text-align:center; font-size:12px; color:#666;'>"
                                f"{caption}<br>[{credit}]</div>",
                                unsafe_allow_html=True,
                            )

                            # 2) ì£¼ì†Œ (ìº¡ì…˜ ë‹¤ìŒ, í˜¼ì¡ë„ ì´ì „)
                            addr_for_ai = area.get("addr") or area.get("address") or ""
                            addr_display = to_road_address(addr_for_ai)
                            if not addr_display and area_name:
                                addr_display = f"ì„œìš¸ {area_name}"
                            if addr_display:
                                with st.container(border=True):
                                    st.write(addr_display)

                            # 3) ì‹¤ì‹œê°„ í˜¼ì¡ë„
                            crowd_badge(crowd_now)

                            # 4) ì¸ê·¼ ì§€í•˜ì² ì—­ ë°•ìŠ¤ (OpenAI ìš°ì„ )
                            stations = get_nearby_stations_openai(openai_key, area_name, addr_for_ai)
                            if not stations:
                                stations = NEARBY_STATIONS.get(area_name, [])
                            if stations:
                                with st.container(border=True):
                                    st.markdown("**ì¸ê·¼ ì§€í•˜ì² ì—­**")
                                    st.write(" / ".join(stations))

                            # 5) ëª…ì†Œ ì •ë³´
                            with st.container(border=True):
                                desc = area.get("description") or ""
                                if desc:
                                    st.write(f"ì„¤ëª…: {to_korean_display(desc)}")
                                homepage = area.get("homepage_url")
                                if homepage:
                                    st.link_button("í™ˆí˜ì´ì§€", homepage)

                            # 7) ë¹„ì„ í˜¸ ì˜µì…˜ (ìš”ì•½ ì¹´ë“œ í•˜ë‹¨) - ì™¸ë¶€ ë°•ìŠ¤ ì œê±°
                            c1, c2 = st.columns([0.7, 0.3])
                            with c1:
                                st.write("")
                            with c2:
                                dislike_key = f"dislike_{signature}_{area_name}_card"
                                disliked_already = area_name in st.session_state.disliked.get(signature, set())
                                checked = st.checkbox("ë¹„ì„ í˜¸", key=dislike_key, value=disliked_already)
                                if checked and not disliked_already:
                                    disliked_set = st.session_state.disliked.get(signature, set())
                                    disliked_set.add(area_name)
                                    st.session_state.disliked[signature] = disliked_set

        # ìƒì„¸ í™”ë©´
        if st.session_state.view == "detail" and st.session_state.selected_area_name:
            st.session_state.used_image_urls = set()
            area = next(
                (x for x in recos if (x.get("area") or "") == st.session_state.selected_area_name),
                None,
            )
            if area is None:
                st.session_state.view = "list"
                st.session_state.selected_area_name = None
                st.rerun()

            area_name = area.get("area") or ""
            if not area_name:
                st.session_state.view = "list"
                st.session_state.selected_area_name = None
                st.rerun()
            crowd_now = area.get("crowd_now", "ì•½ê°„ ë¶ë¹”")

            st.markdown(f"## ìƒì„¸ ì •ë³´: {area_name}")
            if st.button("ëª©ë¡ìœ¼ë¡œ ëŒì•„ê°€ê¸°", type="primary"):
                st.session_state.view = "list"
                st.session_state.selected_area_name = None
                st.rerun()

            # 1) ëŒ€í‘œ ì´ë¯¸ì§€ + ì§€ë„ (ìƒë‹¨ ë‚˜ë€íˆ)
            top_cols = st.columns([0.55, 0.45], gap="large")
            with top_cols[0]:
                img_url, caption, credit, orientation = get_image_and_meta(
                    area_name,
                    indexed_regions,
                    regions_meta,
                    photo_korea_key,
                    st.session_state.used_image_urls,
                )
                if img_url:
                    st.session_state.used_image_urls.add(img_url)
                render_region_card(area_name, crowd_now, img_url, orientation, height_px=300)
                st.markdown(
                    f"<div style='text-align:center; font-size:12px; color:#666;'>"
                    f"{caption}<br>[{credit}]</div>",
                    unsafe_allow_html=True,
                )
            with top_cols[1]:
                center = area.get("center") or (37.5665, 126.9780)
                render_map(center, label=area_name, height_px=300)

            # 2) ìƒì„¸ ì •ë³´ (ë°•ìŠ¤í˜•)
            with st.container(border=True):
                st.markdown("#### ì§€ì—­ ìƒì„¸")
                addr = area.get("addr") or area.get("address") or ""
                addr_display = to_road_address(addr)
                if not addr_display and area_name:
                    addr_display = f"ì„œìš¸ {area_name}"
                if addr_display:
                    st.write(addr_display)
                desc = area.get("description") or ""
                if desc:
                    st.write(f"ì„¤ëª…: {to_korean_display(desc)}")
                homepage = area.get("homepage_url")
                if homepage:
                    st.link_button("í™ˆí˜ì´ì§€", homepage)

            addr_for_ai = area.get("addr") or area.get("address") or ""
            stations = get_nearby_stations_openai(openai_key, area_name, addr_for_ai)
            if not stations:
                stations = NEARBY_STATIONS.get(area_name, [])
            with st.container(border=True):
                st.markdown("#### ì¸ê·¼ ì§€í•˜ì² ì—­")
                if stations:
                    st.write(" / ".join(stations))
                else:
                    st.write("ì¸ê·¼ 500m ì§€í•˜ì² ì—­: (ë°ì´í„° ì¤€ë¹„ í•„ìš”)")

            with st.container(border=True):
                st.markdown("#### ì‹¤ì‹œê°„ í˜¼ì¡ë„")
                crowd_badge(crowd_now, title="ì‹¤ì‹œê°„ í˜¼ì¡ë„")
                # ê³¼ê±° í˜¼ì¡ë„ëŠ” ì‹¤ì œ ë°ì´í„°ê°€ ì—†ìœ¼ë¯€ë¡œ í˜„ì¬ í˜¼ì¡ë„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í‘œì‹œ (ì¶”ì •)
                st.markdown("<div style='height:8px;'></div>", unsafe_allow_html=True)
                crowd_badge(crowd_now, title="1ì‹œê°„ ì „ í˜¼ì¡ë„")
                crowd_badge(crowd_now, title="2ì‹œê°„ ì „ í˜¼ì¡ë„")

            with st.container(border=True):
                st.markdown("#### ì§ì„  ê±°ë¦¬")
                distance_lines = build_distance_lines(
                    st.session_state.people,
                    area,
                    st.session_state.master_pool,
                )
                if distance_lines:
                    for line in distance_lines:
                        st.write(f"- {line}")
                else:
                    st.write("ì¶œë°œ ì§€ì—­ì„ ì…ë ¥í•˜ë©´ ê±°ë¦¬ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤.")

            # 3) ì¶”ì²œ ì´ìœ  / ì½”ìŠ¤ (OpenAI)
            extra_context = {
                "nearby": NEARBY_BEST.get(area_name, []),
                "stations": stations,
                "address": area.get("addr", ""),
            }
            gen = generate_reason_cached(
                openai_api_key=openai_key,
                area_name=area_name,
                crowd_label=crowd_now,
                main_taste=st.session_state.people[0].taste,
                main_purpose=st.session_state.people[0].purpose,
                extra_context=extra_context,
            )

            with st.container(border=True):
                st.markdown("#### ì¶”ì²œ ì´ìœ ")
                bullets = gen.get("bullets") or split_sentences_for_bullets(gen.get("one_liner", ""))
                if bullets:
                    render_bullet_list(bullets[:3])
                else:
                    st.write("ì¶”ì²œ ì´ìœ ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

            with st.container(border=True):
                st.markdown("#### ìƒì„¸ ì½”ìŠ¤ ì¶”ì²œ")
                course = gen.get("course", {}) or {}
                if course:
                    c1, c2 = st.columns(2, gap="medium")
                    with c1:
                        st.markdown("**ì „ì‹œÂ·ë¬¸í™”**")
                        render_bullet_list(course.get("culture", [])[:3])
                        st.markdown("**ì¹´í˜**")
                        render_bullet_list(course.get("cafe", [])[:3])
                    with c2:
                        st.markdown("**ì‹ë‹¹**")
                        render_bullet_list(course.get("food", [])[:3])
                        st.markdown("**ê³µì—°Â·ì²´í—˜**")
                        render_bullet_list(course.get("activity", [])[:3])
                else:
                    st.write("ì½”ìŠ¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

            # ì§€ë„ ë§í¬ (ë°•ìŠ¤)
            with st.container(border=True):
                st.markdown("#### ì§€ë„ ë§í¬")
                naver = naver_map_link(area_name)
                kakao = kakao_map_link(area_name)
                google = google_map_link(area_name)
                # ê°„ë‹¨ SVG ì•„ì´ì½˜ (ì™¸ë¶€ ë¦¬ì†ŒìŠ¤ ë¡œë“œ ì‹¤íŒ¨ ëŒ€ë¹„)
                naver_icon = "data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='16' height='16'><rect width='16' height='16' rx='3' fill='%2303C75A'/><text x='8' y='12' font-size='10' text-anchor='middle' fill='white' font-family='Arial'>N</text></svg>"
                kakao_icon = "data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='16' height='16'><rect width='16' height='16' rx='3' fill='%23FEE500'/><text x='8' y='12' font-size='10' text-anchor='middle' fill='black' font-family='Arial'>K</text></svg>"
                google_icon = "data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='16' height='16'><rect width='16' height='16' rx='3' fill='%23FFFFFF' stroke='%23E0E0E0'/><text x='8' y='12' font-size='10' text-anchor='middle' fill='%23007AFF' font-family='Arial'>G</text></svg>"
                st.markdown(
                    f"""
                    <div style="display:flex; gap:8px; flex-wrap:wrap;">
                      <a href="{naver}" target="_blank" rel="noopener noreferrer"
                         style="flex:1; padding:10px 12px; border-radius:10px; border:1px solid #e0e0e0;
                                text-decoration:none; font-weight:600; color:#111; background:#fff;
                                display:flex; align-items:center; justify-content:center; gap:6px;">
                        <img src="{naver_icon}" style="width:16px; height:16px;" alt="naver icon">
                        ë„¤ì´ë²„ ì§€ë„
                      </a>
                      <a href="{kakao}" target="_blank" rel="noopener noreferrer"
                         style="flex:1; padding:10px 12px; border-radius:10px; border:1px solid #e0e0e0;
                                text-decoration:none; font-weight:600; color:#111; background:#fff;
                                display:flex; align-items:center; justify-content:center; gap:6px;">
                        <img src="{kakao_icon}" style="width:16px; height:16px;" alt="kakao icon">
                        ì¹´ì¹´ì˜¤ ì§€ë„
                      </a>
                      <a href="{google}" target="_blank" rel="noopener noreferrer"
                         style="flex:1; padding:10px 12px; border-radius:10px; border:1px solid #e0e0e0;
                                text-decoration:none; font-weight:600; color:#111; background:#fff;
                                display:flex; align-items:center; justify-content:center; gap:6px;">
                        <img src="{google_icon}" style="width:16px; height:16px;" alt="google icon">
                        êµ¬ê¸€ ì§€ë„
                      </a>
                    </div>
                    """,
                    unsafe_allow_html=True,
                )

            # 4) í•¨ê»˜ ë°©ë¬¸ ì¶”ì²œ
            with st.container(border=True):
                st.markdown("#### í•¨ê»˜ ë°©ë¬¸ ì¶”ì²œ")
                nearby = NEARBY_BEST.get(area_name, [])
                show6 = nearby[:6]
                if show6:
                    for n in show6:
                        st.write(f"- {n}")
                else:
                    st.write("ì¸ê·¼ ì¶”ì²œ ë°ì´í„° ì¤€ë¹„ í•„ìš”")

            st.markdown("---")
            # 5) ë¹„ì„ í˜¸ ì˜µì…˜ (ìƒì„¸ í™”ë©´) - ë§¨ í•˜ë‹¨ ë°°ì¹˜
            with st.container(border=True):
                st.markdown("#### ë¹„ì„ í˜¸")
                st.caption("ì„ íƒí•˜ë©´ í•´ë‹¹ ì¹´ë“œë§Œ êµì²´ ì¶”ì²œë˜ë©°, ê°™ì€ ì¡°ê±´ì—ì„œëŠ” ë‹¤ì‹œ ì¶”ì²œë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                dislike_key = f"dislike_{signature}_{area_name}"
                disliked_already = area_name in st.session_state.disliked.get(signature, set())
                checked = st.checkbox("ë¹„ì„ í˜¸ë¡œ í‘œì‹œ", key=dislike_key, value=disliked_already)
                if checked and not disliked_already:
                    disliked_set = st.session_state.disliked.get(signature, set())
                    disliked_set.add(area_name)
                    st.session_state.disliked[signature] = disliked_set


if __name__ == "__main__":
    main()
